\section{Introduction}
  In this paper, we are interested in deciding properties of graphs defined in monadic second-order logic.
A series of results by Courcelle deals with this question; in particular \cite{courcelle} proves that every MSO property is decidable in linear time, given a graph with bounded treewidth (encoded by its transition matrix).
Now what if the graph is not typical, but presents some structure that allows a shorter encoding?
Assume that the graph is described succintly, i.e, by a Boolean circuit which computes the adjacency relation between nodes, which are represented by binary numbers.
One natural question is whether it is possible to exploit the circuits in better ways than just querying for possible edges, in order to more directly deduce structural information about the transition graph.
Our main result essentially tells that it is impossible as soon as the property is non-trivial for bounded treewidth graphs.
\begin{theorem}\label{t:succinct}
  If $\phi$ is an arborescent MSO sentence,
  then testing $\phi$ on graphs represented succinctly is either {\ensuremath{\mathsf{NP}}}- or {\ensuremath{\mathsf{coNP}}}-hard.
\end{theorem}
\emph{Arborescent} means that $\phi$ has infinitely many models with some fixed treewidth,
and infinitely many countermodels with some fixed treewidth.
Formal definitions appear in Section~\ref{sec:pre}, including a definition of \emph{treewidth}.
Many of the properties considered in the literature so far.

Our motivation comes from the world of automata networks.

An \emph{automata network} (AN) can be seen as a computer network where all machines hold a local state and update synchronously by reading neighboring states and applying a local transition.
One of the initial intents behind this definition was to model the dynamics of gene regulation~\cite{k69,t73,tt95,ma98,epa04,ks08}.
Nowadays, automata networks are also used as a setup for distributed algorithms and as a modelling tool in engineering.
Those applications have motivated the study of automata network \emph{per se}
and many theoretical properties were found~\cite{e59,g67,c71,r86,gm90,a08,r11,dns12}.

Let us give a slightly more formal description of automata networks.
An AN is given by a finite digraph, called \emph{communication graph}, where each node is endowed with a local update function.
The graph is directed, so one-way transfer of information is possible.
Different automata may have different transition tables and state sets.
To update a node $v$ of the network, first collect the states of its inbound neighbors into a tuple,
and then feed that tuple as an input symbol to the update function of $v$.
Globally speaking, all nodes are updated synchronously (though an extensive literature has explored other \emph{update modes}~\cite{ds20}),
so that the state of $v$ at time $t+1$ only depends on the states of its neighbors at time $t$.

This description suggests an alternative way to think about automata networks:
they can be seen as a generalization of finite cellular automata.
The generalization resides in that the ``grid'' of an AN can be an arbitrary (finite) digraph,
rather than just a regular grid.
Besides, each cell gets its own update function, so no uniformity is enforced.
That analogy between automata networks and cellular automata is relevant,
as we often meet the same sort of research problems in both cases:
information needs to flow in the network to enable nodes to perform useful tasks,
so we need to understand what can or cannot be transmitted efficiently, and where.


In general, the automata in a network may be nondeterministic, so that the network as a whole may be nondeterministic.
Hence we need to consider network updates as a relation,
rather than a function.
We now formalize this idea.
Let $F$ denote an automata network.
A \emph{configuration} of $F$ is a possible state of the whole system, i.e., an assignment of a state to each node.
If configuration $x_1$ evolves in one round into configuration $x_2$, then we say that $x_1$ \emph{transitions} to $x_2$.
We sometimes say that $x_1$ is a \emph{predecessor} of $x_2$, or that $x_2$ is a \emph{successor} of $x_1$.
In general, automata networks are nondeterministic, so that a given configuration might have several successors.

The concepts of \emph{predecessor} and \emph{sucessor} allow to state virtually all interesting questions about $F$.
For instance:
\begin{itemize}
\item Is $F$ deterministic, i.e., do all configurations have exactly one successor?
  If not, how many configurations have more than one successor?
  How many have none?
  What is the maximal number of successors for a configuration?
\item Is $F$ injective, i.e., do all configurations have exactly one predecessor?
  How many have more than one? Or none?
  What is the maximal number of predecessors?
\item Does $F$ have a fixed point, i.e., a configuration that is its own successor?
  How many are there?
\item Does $F$ have a cycle of configurations?
  (A sequence of configurations $x_0,\dots,x_{k-1}$ such that $x_i$ transitions to $x_{i+1}$, with indices taken modulo $k$.)
  How many of them does it have? What are their lengths?
\end{itemize}
The \emph{transition graph} of $F$, denoted by $\TG{F}$, is the digraph of the \emph{transition} relation.
In other terms, its vertices are the configurations of $F$ and there is an edge from configuration $x_1$ to configuration $x_2$ if $x_1$ transitions to $x_2$.
The transition graph is exponentially bigger than the communication graph.
That graph describes the dynamical behavior of $F$: all the questions above (and many more) are actually questions about $\TG{F}$ rather than $F$.

We are interested in testing properties of $\TG{F}$, given $F$ as input.
When given as input to an algorithm, $F$ is encoded through a Boolean circuit that, given two integer sequences $z_1,\dots,z_n$ and $z'_1,\dots,z'_n$ in binary, returns whether or not the first configuration can transition into the second one.
This corresponds to a succinct representation for $\TG F$.

While seemingly artificial, this encoding is relevant for applications.
When automata networks are used to model actual computer networks, it is reasonable to assume access only to the source code of the programs run by the nodes.
Boolean circuits represent this source code.
Similarly in biology, experimental observations show how each pair of nodes (in this case, genes) influence each other;
for a given node, the influences should be summed or otherwise accumulated.
This data does not give a complete transition table for each node, but can easily be encoded as Boolean circuits.
If a transition table happens to be available, it can be re-encoded as a circuit quickly and efficiently without sacrificing much space.

In a sense, designing algorithms (respectively, hardness results) for automata network is like designing algorithms (respectively, hardness results) for succinct graphs.
In particular, every graph is the transition graph of an automata network, i.e.,
for every graph $G=(V,E)$ there is an automata network $F$ such that $\TG{F}=G$
(we can choose $F$ with just one nondeterministic automaton having $|V|$ states).
The results from~\cite{ggpt21} already hint that the encoding cannot be smartly used to efficiently solved some questions.
For instance,
\begin{theorem}[see~\cite{ggpt21}]
  \label{thm:fo}
  Let $\phi$ denote a question about graphs expressible in first-order logic.
  It is either $O(1)$, or {\ensuremath{\mathsf{NP}}}-hard, or {\ensuremath{\mathsf{coNP}}}-hard, given a deterministic automata network $F$ as input, whether $\TG{F}$ satisfies $\phi$.
\end{theorem}

In particular, first-order logic cannot express any non-trivial polynomial-time solvable question about the dynamics of automata networks, unless ${\ensuremath{\mathsf{P}}}={\ensuremath{\mathsf{NP}}}$.
This is a strong indication that it is indeed not tractable to analyze the Boolean circuits given to us in order to extract structural information about the dynamics: the best we can do is to evaluate the circuits to explore the transition graph.
The intuition behind this hardness result is that automata networks are morally a model of computation,
so they are subjected to some analogue of Rice's theorem:

\begin{theorem}[see~\cite{r53}]
  \label{thm:rice}
  Any nontrivial property of the function computed by a Turing machine is undecidable.
\end{theorem}

The ``function computed by a Turing machine'' in Theorem~\ref{thm:rice} compares to ``property of $\TG{F}$'' in Theorem~\ref{thm:fo},
while ``undecidable'' compares to ``${\ensuremath{\mathsf{NP}}}$-hard or ${\ensuremath{\mathsf{coNP}}}$-hard'' and ``trivial'' compares to ``$O(1)$''.
There is no hope to obtain undecidability results on automata networks because $\TG{F}$ is a finite object:
we can always enumerate all configurations of $F$ and reconstruct $\TG{F}$, then test whatever we want on it.
That would take exponential space, though, so it makes sense to try and find more direct algorithms or hardness results for questions about $\TG{F}$.
What we show is that such algorithms, under standard complexity assumptions (${\ensuremath{\mathsf{P}}}\neq{\ensuremath{\mathsf{NP}}}$), cannot run in polynomial time.

There are other ``Rice theorems'' for models of computation, e.g., cellular automata: see~\cite{k94}.

\paragraph{Contributions.}

The present work started as an attempt to generalize Theorem~\ref{thm:fo} in two directions:
from first-order logic (FO) to monadic second-order logic (MSO),
and from deterministic automata networks to nondeterministic networks.
Neither generalization is trivial.

\emph{Questions about general ANs are harder than questions about deterministic ANs.}
For instance, the question ``is $F$ deterministic?'' is expressible in FO.
If we restrict ourselves to deterministic ANs, that question is $O(1)$; in general, it is not.
Thence the generalization requires to prove, in particular, that determinism is either {\ensuremath{\mathsf{NP}}}- or {\ensuremath{\mathsf{coNP}}}-hard.

\emph{Questions in MSO are stronger than questions in FO.}
For instance, MSO can express ``$\TG{F}$ is connected'', while FO cannot.
Thence we need to prove, in particular, that connectedness of the transition graph is either {\ensuremath{\mathsf{NP}}}- or {\ensuremath{\mathsf{coNP}}}-hard.

Hardness of connectedness and determinism will both be consequences of our main result, Theorem~\ref{thm:mso}.
In addition to being technically harder, both generalizations are useful.
Indeed, when restricting ourselves to deterministic networks, we restrict ourselves to transition graphs of out-degree one.
This is not very exciting from the perspective of graph theory.
The generalization to nondeterministic networks lifts that restriction,
which enables future work to explore deeper connections between automata networks, Boolean circuits, and graph combinatorics.
Moreover MSO logic allows to express the relation ``there is a chain of transitions from configuration $x$ to configuration $y$'',
which FO cannot.
That relation naturally arises in many practical questions.

Things turned out more complicated than expected, and we do not get a general result.
\begin{theorem}
  \label{thm:mso}
  If $\phi$ is an \emph{arborescent} MSO sentence,
  then testing $\phi$ on the transition graph of automata networks is either {\ensuremath{\mathsf{NP}}}- or {\ensuremath{\mathsf{coNP}}}-hard.
\end{theorem}
This theorem rephrases Theorem~\ref{t:succinct}.
Many of the properties considered in the literature so far, and in particular questions mentioned earlier in this introduction, are arborescent (up to turning counting questions into decision questions in the usual way,
so ``how many fixpoints are there?'' becomes ``are there more than $k$ fixpoints?'' for a fixed $k$).

The \emph{arborescent} condition is crucial in our proofs, since it gives the existence of regular families of models and countermodels on which to build a polynomial reduction.
It is natural to ask whether it is necessary.
In Section~\ref{sec:bad}, we give the following partial answer:

\begin{theorem}
  \label{thm:noarb}
  There is a (nonarborescent) first-order sentence $\psi$ such that,
  under plausible complexity assumptions,
  testing $\psi$ in the transition graph of a given AN is neither
  constant time, nor {\ensuremath{\mathsf{NP}}}-hard, nor {\ensuremath{\mathsf{coNP}}}-hard.
\end{theorem}

\paragraph{Contents.}
\begin{itemize}
\item In Section~\ref{sec:pre}, we give the definitions and notations.
\item In Section~\ref{sec:stmt}, we restate the main result and give a proof outline.
\item In Sections~\ref{sec:saturating}--\ref{sec:sat}, we prove the main result;
  their respective roles are explained in the proof outline in Section~\ref{sec:stmt}.
  Readers willing to skip the technical details can safely skip these sections.
\item In Section~\ref{sec:bad}, we discuss nonarborescent sentences.
\item We conclude with a discussion and a few suggestions for further research.
\end{itemize}

\section{Definitions}
\label{sec:pre}

\paragraph{Automata networks.}
An \emph{automata network} is a finite digraph $F=(V,E)$ where each node $v$ is equipped with a finite \emph{state set} $Q_v$ and
a \emph{local function} (also called \emph{transition function}):
\begin{equation*}
  f_v: \left(\prod_{(u,v)\in E} Q_u\right) \to Q_v.
\end{equation*}
A \emph{configuration} is an assignment of a state to each node; formally, it is an element of $\prod_{u\in V} Q_u$.
If $x$ is a configuration and $v$ a node of $F$, we write $x_v$ for the state of $v$ in $x$; formally, it is the projection~$\pi_v(x)$.
The \emph{updated configuration} $F(x)$ is the configuration given by:
\begin{equation*}
  F(x)_v=f_v\left(\prod_{(u,v)\in E} x_u\right),
\end{equation*}
for every $v$ in $V$.
As the notation $F(x)$ suggests,
we often view an automata network as a \emph{global function}:
\begin{equation*}
  F:\prod_{u\in V} Q_u \to \prod_{u\in V} Q_u
\end{equation*}
from the set of configurations to itself.

We will consider \emph{nondeterministic} automata networks throughout this paper, unless specified otherwise.
The global function $F$ becomes a \emph{global relation}
$F\subseteq\prod_{u\in V} Q_u \times \prod_{u\in V} Q_u$ (or equivalently a ``multi-valued functions''), which tells whether a configuration can transition to another one.
The terminology and notation of the deterministic case carry over to nondeterministic networks.
This global nondeterminism can come from the Cartesian product of local nondeterministic $f_v\subseteq\prod_{u\in V}Q_u\times Q_v$ (a natural definition for nondeterministic automata networks), but it is generally not enough.
For instance, a particle moving nondeterministically on a graph cannot be modeled be a Cartesian product of local nondeterministic choices made at each node, correlation between choices of neighboring nodes is required.
To emphasize the locality of transitions in the general case, a nondeterministic automata network can be defined by $F=\{(x,y) : \forall U\in\mathcal U,(x_U,y_U)\in f_U\}$, where $\mathcal U$ is a set of subsets of $V$, and for each of its elements $U\in\mathcal U$, $f_U\subseteq\prod_{u\in U}Q_u\times\prod_{u\in U}Q_u$ is a relation ``located'' over $U$.




  

\begin{remark}
  The automata networks constructed in our proof cannot generally be obtained through the Cartesian product of local determinism, but they are non-deterministic in a very weak sense: each configuration has only a bounded number of images (the transition graph has bounded degree).
  The bound depends only on
  the formula.
  This makes the result stronger that it is actually stated.
\end{remark}

Another point of view is that of \emph{succinct graph representations},
where the communication graph and the locality of map $F$ is discarded while describing the graph $\TG{F}$.
A graph $G$ is said to be \emph{succinctly represented} as a pair $(N,C)$,
where $C$ is a Boolean circuit on $2n$ inputs and one output and $N$ is an integer (encoded in binary) with ${N\leq 2^n}$,
whenever there is a one-to-one labeling of the vertices of $G$ onto ${\{0,\cdots,N-1\}}$ such that ${C(x,y)=1}$ if and only if there is an edge from the vertex labeled $x$ to the vertex labeled $y$.

It is easy to transform an automata network $F$ encoded as above into a succinct graph representation of ${\TG{F}}$.
Conversely, one can see a succinct representation ${(N,C)}$ of a graph $G$ as a (degenerate) automata network with just one node and $N$ states whose transition graph is $G$.

We always assume that a Boolean circuit is not bigger than its transition table:
if it were, we could
encode the table into a circuit of the same size (up to a polynomial factor).

\paragraph{MSO Logic.}
Given an automata network $F$, we want to test Monadic Second-Order logic formulae inside its transition graph $\TG{F}$.
MSO formulae have two kinds of variables: vertices ($x_1, x_2, \dots$) and sets of vertices ($X_1, X_2, \dots$)---in our case, vertices are configurations.
Accordingly, there are two kinds of existential quantifiers: existence of a configuration, and existence of a set of configurations.
The Boolean connectives $\neg$ and $\wedge$ are as usual.
The universal quantifiers, bounded quantifiers and other Boolean connectives are derived from them.
The atoms are: equality ($x_1=x_2$),
membership ($x_1\in X_1$),
and transition ($F(x_1, x_2)$, meaning $F(x_1)=x_2$ or more correctly $x_2\in F(x_1)$).
Note that the transition symbol $F$ is a relational symbol in our signature, \textbf{not} a functional symbol.

A \emph{sentence} is a closed monadic second-order formula, i.e., one where all variables are bound to a quantifier.
Here are some examples:
\begin{itemize}
\item \emph{(Existence of a fixed point)} $\exists x: F(x,x)$.
\item \emph{(Unicity of fixed point)} $\forall x, \forall x': F(x,x) \wedge F(x',x') \implies x=x'$.
\item \emph{(Injectivity)} $\forall y, \forall x, \forall x': F(x,y) \wedge F(x',y)\implies x=x'$.
\item \emph{(Determinism)} $\forall x, \forall y, \forall y': F(x,y) \wedge F(x,y')\implies y=y$.
\item \emph{(Nontrivial cycle)} $\exists X,[\exists x\in X]\wedge[\forall x\in X,\exists y\in X:x\neq y\wedge F(x,y)]$.
\end{itemize}
With this MSO signature, it is possible to express as a macro the relation $F^*(x,y)$: ``there exists a chain $x=z_1,z_2,\dots,z_{n-1},z_n=y$ such that $F(z_{k},z_{k+1})$ holds for every $1\leq k\leq n-1$.''
On the other hand, it is not possible to express something like: ``all configurations have the same out-degree.''
See~\cite{l04} or~\cite{df13} for more information about MSO logic in graphs.

\paragraph{Tree decompositions.}
A \emph{tree decomposition} of a graph $G=(V,E)$ is a tree $T$ whose nodes are labeled with subsets of $V$%
---called \emph{bags}---
satisfying the three conditions below.
If $p$ is a node of $T$, we write $B(p)$ for its label, i.e., the corresponding bag.
\begin{enumerate}[label=(\roman*)]
\item Every node of $G$ belongs to at least one bag.
\item For every edge $(v_1,v_2)$ of $G$, there is at least one bag in $T$ containing both $v_1$ and $v_2$.
\item For all nodes $p,q,r$ of $T$, if $q$ is on the (unique) path from $p$ to $r$,
  then $B(p)\cap B(r) \subseteq B(q)$.
\end{enumerate}
That definition is usually stated for undirected graphs, but it works without change for directed graphs.
In other terms, we look at tree decompositions of the symmetric closures of the considered graphs.
A graph has, in general, many different tree decompositions.
The \emph{width} of a decomposition is the size of its largest bag minus one.
The \emph{treewidth} of a graph is the minimal width among all of its tree decompositions.
For every integer $k$, a \emph{$k$-tree decomposition} means a tree decomposition of width $k$.
In this paper, any tree (including tree decompositions) is regarded as rooted and oriented downwards: edges point away from root.

\paragraph{Additional conventions.}
If $G$ is a graph, let $|G|$ denote the number of its nodes, dubbed its \emph{size}.
If $S$ is an instance of SAT, let $|S|$ denote the number of its variables, also dubbed its \emph{size}.
If $\phi$ is an MSO sentence, its \textbf{quantifier rank} is its number of quantifiers
(not the number of alternances).
Unless stated otherwise: \textbf{increasing} means strictly increasing;
\textbf{integer} means positive or null integer;
\textbf{polynomial} means nonconstant polynomial with integer coefficients.

\section{Statement of the main result and proof outline}
\label{sec:stmt}

\paragraph{The problem.}
Given an MSO sentence $\phi$, define the problem $\phi$\textsc{-Dynamics} as follows:
\begin{enumerate}[label=]
\item $\phi$\textsc{-Dynamics}
\item \emph{Input:} an automata network $F$ (given as Boolean circuits for the local relation of each node).
\item \emph{Output:} does $\TG{F}\models\phi$?
\end{enumerate}
Observe that $\phi$ is \emph{not} part of the input: it is considered constant.
In other words, we have a family of problems parameterized by MSO sentences.

Analogously, we can define the model checking problem of $\phi$ on graphs given by a succinct representation.
\begin{enumerate}[label=]
\item \textsc{Succinct-}$\phi$
\item \emph{Input:} a succinct representation ${(C,N)}$ of some graph $G$.
\item \emph{Output:} does $G\models\phi$?
\end{enumerate}

Following the remarks on automata networks encoding and succinct representations, it is straightforward to show that for any MSO formula $\phi$ the problems $\phi$\textsc{-Dynamics} and \textsc{Succinct-}$\phi$ are \textsf{LOGSPACE}-equivalent.
Our main result is the following.

\begin{theorem}
  \label{thm:main}
  If $\phi$ has infinitely many models with the same treewidth $k_1$ and infinitely many countermodels with the same treewidth $k_2$,
  then $\phi$\textsc{-Dynamics} is either {\ensuremath{\mathsf{NP}}}-hard or {\ensuremath{\mathsf{coNP}}}-hard.
  The result still holds if we restrict inputs of $\phi$\textsc{-Dynamics} to automata networks with bounded non-determinism (transition graph with outdegree at most $k$, for large enough $k$ depending on $\phi$).
\end{theorem}

It can also be phrased as a counterpoint to Courcelle's theorem, as follows:
\begin{corollary}
  If $\phi$ is an MSO property with infinitely many models and countermodels among graphs of bounded treewidth, then the problem \textsc{Succinct-}$\phi$ is either {\ensuremath{\mathsf{NP}}}-hard or {\ensuremath{\mathsf{coNP}}}-hard.
  The result still holds if we restrict to graphs of bounded degree.
\end{corollary}

An MSO sentence is \emph{arborescent} if it satisfies the condition of Theorem~\ref{thm:main}.
All examples of sentences given in the previous section are arborescent.
We will deal with non-arborescent sentences in Section~\ref{sec:bad}.

\paragraph{Proof outline.}
First, we show that there exists a ``good'' graph, call it $\Omega$,
such that $\Omega\sqcup G$ is always a model of $\phi$ (where $\sqcup$ denotes disjoint union),
no matter what $G$ is.
Then, we show that there exists a ``bad'' graph, say $Y$,
such that $Y\sqcup\dots\sqcup Y$ is always a countermodel of $\phi$, no matter how many disjoint copies of $Y$ we put.
We can arrange things so that $\Omega$ and $Y$ have the same number of vertices.

Now we perform a reduction: we are given an instance $S$ of SAT with $s$ Boolean variables,
and we produce an automata network $F$ such that $\TG{F}\models\phi$ if and only if $S$ has at least one positive assignment.
The network $F$ has $s$ automata with two states ($0$ and $1$) and one ``big'' automaton with $|\Omega|=|Y|$ states.
What $F$ does is interpret the states of the $s$ Boolean automata as an assignment for the variables of $S$, and evaluate $S$ on that assignemnt.
If it finds ``true'', then the big automaton transitions so as to realize a copy of $\Omega$ in $\TG{F}$.
If it finds ``false'', then the big automaton realizes a copy of $Y$ instead.
(The Boolean automata never change their states.)
Consequently, $\TG{F}$ contains as many copies of $\Omega$ as positive assignments for $S$,
and as many copies of $Y$ as negative assignments for $S$.
This completes the reduction: if there is at least one positive assignment, the defining property of $\Omega$ guarantees that the dynamics satisfies $\phi$.
Otherwise, the dynamics is only a pack of disjoint copies of $Y$, which does not satisfy $\phi$.

This whole construction can be performed in polynomial time because $\Omega$ and $Y$ do not depend on $S$:
they only depend on $\phi$, hence they are constants.
(Recall that $\phi$ is \emph{not} part of the input of the problem.)
The only part of $F$ that depends on $\phi$ is the evaluation of $S$, but automata network are encoded as Boolean circuits.
It is easy, given an instance of SAT, to produce in polynomial time circuits that evaluate a given assignment.

\smallskip
Of course, things are not that simple.
First problem: we will not be able to control whether $\Omega$ (called a \emph{saturating graph}) turns any graph into a model or into a countermodel.
If it so happens that $\Omega$ turns any graph into a countermodel,
then we will have to symmetrize all the remainder of the proof (in particular, $Y\sqcup\dots\sqcup Y$ will have to be a model),
and in that case we will get {\ensuremath{\mathsf{coNP}}}-hardness instead of {\ensuremath{\mathsf{NP}}}-hardness.
On the other hand, it turns out that $\Omega$ does not depend on $\phi$, but only on the quantifier rank of $\phi$,
which is pretty amusing.
The details are explained in Section~\ref{sec:saturating}.

Second problem: we have to relax the requirements on $Y$.
What we will actually get is a triple of graphs $(X,Y,Z)$ such that $X\oplus Y\oplus \dots\oplus Y\oplus Z$ is a countermodel of $\phi$ (or, if needed, a model of $\phi$), no matter how many copies of $Y$ are in there.
The gluing operator $\oplus$ is more general than disjoint union; $G\oplus G'$ basically means:
``take the disjoint union of $G$ and $G'$, but also merge some designated vertices of $G$ with designated vertices of $G'$''.
The details are explained in Section~\ref{sec:pump}
(for notational convenience, $X,Y,Z$ are called $G_1,G_2,G_3$ in that section---the subscripts come in handy).

Third problem: because of the concessions just made on $Y$,
the reduction from SAT described above does not work anymore.
Indeed we have to make some space for $X$ and $Z$ in the dynamics of $F$,
and we have to account for the merged vertices (per definition of $\oplus$).
This requires care, because we cannot allow any extraneous configuration in the dynamics:
every single configuration has to belong to the (unique) copy of $X$, the (unique) copy of $Z$,
some copy of $Y$, or some copy of $\Omega$.
The details are explained in Section~\ref{sec:sat}, which also includes the final proof of Theorem~\ref{thm:main}.

Sections~\ref{sec:saturating}, \ref{sec:pump} and~\ref{sec:sat} each start with a proposition, and the remainder of the section is the proof of the proposition.
These three propositions together quickly yield a proof for Theorem~\ref{thm:main}.

\section{A graph saturating all sentences of fixed quantifier rank}
\label{sec:saturating}

\begin{proposition}
  \label{pro:saturating}
  Fix $m\in\mathbb{N}$.
  There exists a graph $\Omega_m$ such that,
  for every MSO sentence $\phi$ of rank $m$, either:
  \begin{enumerate}[label=(\roman*)]
  \item for every graph $G$, we have $G\sqcup\Omega_m\models\phi$; or
  \item for every graph $G$, we have $G\sqcup\Omega_m\not\models\phi$.
  \end{enumerate}
\end{proposition}

In the first case, we say that $\Omega_m$ is a \emph{sufficient subgraph} for $\phi$;
in the second case, $\Omega_m$ is a \emph{forbidden subgraph} for $\phi$.
A graph that is either sufficient or forbidden for a given sentence is called \emph{saturating} for that sentence.
The rest of this section is a proof of Proposition~\ref{pro:saturating}.

If $G$ and $G'$ are graphs, write $G\equiv_m G'$ if and only if $G$ and $G'$ satisfy exactly the same MSO sentences of quantifier rank $m$.
Write $G\sqcup G'$ for the disjoint union of a copy of $G$ and a copy of $G'$.
If $k$ is an integer, write $\bigsqcup^k G$ the disjoint union of $k$ copies of $G$.

\begin{lemma}
  \label{lem:qexists}
  For every nonempty graph $G$,
  there exists an integer $q(G,m)$ such that $\bigsqcup^{q(G,m)} G\equiv_m \bigsqcup^{q(G,m)+1} G$.
\end{lemma}
\begin{proof}
  We show that there exists an integer $q(G,m_1,m_2)$ such that,
  in the MSO-Ehrenfeucht-Fraïssé game over the graphs
  \begin{equation*}
    \gamma=\bigsqcup\nolimits^{q(G,m_1,m_2)} G \hspace{1cm}\text{and}\hspace{1cm} \gamma'=\bigsqcup\nolimits^{q(G,m_1,m_2)+1} G,
  \end{equation*}
  if Spoiler plays at most $m_1$ point moves and $m_2$ set moves,
  then Duplicator wins.
  (For more details about MSO-Ehrenfeucht-Fraïssé games, see Section~7.2 of~\cite{l04}.)
  To conclude the proof, it will suffice to set $q(G,m)=\max \{q(G,m_1,m_2) : m_1+m_2=m\}$.
  Reason by induction over $m_2$.
  
  If $m_2=0$, then Spoiler only plays point moves.
  Set $q(G,m_1,0)=m_1$.
  Since the game lasts $m_1$ turns, Spoiler touches at most $m_1$ copies of $G$ in $\gamma'$,
  thus they cannot point any difference with $\gamma$.

  If $m_2>0$, then set:
  \begin{equation*}
    \log_2\left( q(G,m_1,m_2) \right) = |G|\cdot \left(q(G,m_1,m_2-1)+m_1+m_2\right).
  \end{equation*}
  Call $\gamma_i$ (respectively $\gamma'_i$) the $i^{\mbox{\scriptsize th}}$ copy of $G$ in $\gamma$ (respectively $\gamma'$),
  for $1\leq i\leq q(G,m_1,m_2)$ (respectively $1\leq i\leq q(G,m_1,m_2)+1$).
  If Spoiler starts by playing a point move in $\gamma_i$,
  then Duplicator chooses the same vertex in $\gamma'_i$.
  The case of Spoiler playing in $\gamma'_i$ is symmetric:
  up to reordering the $\gamma'_i$, we can assume that Spoiler never plays in $\gamma'_{q(G,m_1,m_2)+1}$.
  Duplicator continues this strategy as long as Spoiler plays point moves.

  Now consider the first set move of Spoiler and suppose that it was in $\gamma$.
  Recall that we can assume no point move took place in $\gamma'_{q(G,m_1,m_2)+1}$.
  Spoiler just pointed a subset of vertices of $\gamma$,
  or equivalently pointed a subset of vertices of each $\gamma_i$ separately.
  Call $V_1,\dots,V_{2^{|G|}}$ all possible subsets of vertices of $G$ and $f:\{1,\dots,q(G,m_1,m_2)\}\to\{1,\dots,2^{|G|}\}$ the function such that for each $\gamma_i$,
  Spoiler pointed $V_{f(i)}$.
  For $1\leq i\leq q(G,m_1,m_2)$, Duplicator plays in $\gamma'_i$ the set $V_{f(i)}$,
  i.e., the same set of vertices as Spoiler played in $\gamma_i$.
  It remains to play a set of vertices for $\gamma'_{q(G,m_1,m_2)+1}$:
  choose $n$ such that $|f^{-1}(n)|> q(G,m_1,m_2-1)$ and play $V_n$.

  Call $f'$ the function such that, for every $i$, Duplicator played $V_{f'(i)}$ in $\gamma'_i$.
  To finish the game, Duplicator actually plays $2^{|G|}$ games in parallel,
  one in each couple of graphs $(f^{-1}(n), f'^{-1}(n))$ for $1\leq n\leq 2^{|G|}$.
  All those couples of graphs either have the same number of copies of $G$ inside,
  or both have more than $q(G,m_1,m_2-1)$ copies of $G$, and Duplicator wins by induction.

  Symmetrically, suppose that the first set move of Spoiler was in $\gamma'$.
  Up to reordering the $\gamma'_i$,
  we can suppose both that no point move took place in $\gamma'_{q(G,m_1,m_2)+1}$
  and that $|f'(q(G,m_1,m_2)+1)|>q(G,m_1,m_2-1)$.
  In $\gamma_i$, Duplicator plays the set $V_{f(i)}$.
  To finish the game, Duplicator actually plays $2^{|G|}$ games in parallel,
  one in each couple of graphs $(f^{-1}(n), f'^{-1}(n))$ for $1\leq n\leq 2^{|G|}$.
  Once again all those couples of graphs either have the same number of copies of $G$ inside,
  or both have more than $q(G,m_1,m_2-1)$ copies of $G$, so Duplicator wins by induction.
\end{proof}

\begin{lemma}[Proposition~7.5 from~\cite{l04}]
  For every $m$, the relation $\equiv_m$ has finitely many equivalence classes.
\end{lemma}

Call $a(m)$ the number of classes of $\equiv_m$ and let $A_1,\dots,A_{a(m)}$ denote representatives of each class.

\begin{proof}[Proof of Proposition~\ref{pro:saturating}.]
  Define $\Omega_m$ as follows: take $q(A_i,m)$ disjoint copies of $A_i$, for $i$ ranging in $\{1,\dots,a(m)\}$.
  We show that $\Omega_m$ is either a forbidden or a sufficient subgraph for $\phi$.
  for every graph $G$, we have $G \equiv_m A_i$ for one $i$ in $\{1,\dots,a(m)\}$.
  Hence $\Omega_m \sqcup G \equiv_m \Omega_m \sqcup A_i$:
  in the MSO-Ehrenfeucht-Fraïsé game between those graphs,
  Duplicator can apply its winning strategies separately in $\Omega_m$ and in $G/A_i$.
  Consequently, adding $G$ to $\Omega_m$ is equivalent to adding a $[q(A_i,m)+1]^\text{\scriptsize th}$ copy of $A_i$ to $\Omega_m$.
  By definition of $q$ in Lemma~\ref{lem:qexists}, the resulting graph is equivalent to $\Omega_m$.
  As a conclusion, $\Omega_m\equiv_m \Omega_m\sqcup G$, and whether it is a model of $\phi$ or not does not depend on $G$.
\end{proof}

\section{Pumping models of arborescent sentences}
\label{sec:pump}

A \emph{boundaried graph} is a digraph $G$ endowed with an additional specific sequence $P=(p_0,\dots,p_{k-1})$ of distinct nodes of $G$, called \emph{ports}.
The set of vertices, of edges and of ports of a boundaried graph $G$ are denoted by $V(G)$, $E(G)$ and $P(G)$ respectively.
If $G$ and $G'$ denote boundaried graphs with the same number of ports,
then $G\oplus G'$ (``$G$ glued to $G'$'') is defined as the graph $G\sqcup G'$ where the $i^\text{\scriptsize th}$ port of $G$ is merged with the $i^\text{\scriptsize th}$ port of $G'$.

A \emph{$k$-biboundaried graph}, or $k$-graph for short, is a digraph $G$ endowed with two sequences of $k$ ports:
the \emph{primary ports}, denoted by $P_1(G)$, and the \emph{secondary ports}, denoted by $P_2(G)$.
(So we have $|P_1(G)|=|P_2(G)|=k$.)
For two such graphs $G$ and $G'$, write $G\oplus G'$ for $G\sqcup G'$ where $P_2(G)$ is identified with $P_1(G')$.
Moreover, set $P_1(G\oplus G')=P_1(G)$ and $P_2(G\oplus G')=P_2(G')$.
Note that $P_1(G)$ and $P_2(G)$ may intersect.
Now let $\Gamma=\{G_i\}_{i\in I}$ be a finite family of $k$-graphs;
if $w$ is a nonempty word over alphabet $I$, then define $\Delta^\Gamma(w)$ by induction over the length of $w$ as follows:
\begin{equation*}
  \Delta^\Gamma(w_1)=G_{w_1},
  \hspace{1cm}
  \Delta^\Gamma(w_1\dots w_{n}) = \Delta^\Gamma(w_1\dots w_{n-1})\oplus G_{w_{n}}.
\end{equation*}
See Figure~\ref{fig:gpack}---although the possibility that $P_1$ and $P_2$ intersect is not shown on that figure.

\begin{proposition}
  \label{pro:pump}
  Let $\phi$ denote an MSO sentence and $k$ an integer.
  If $\phi$ has infinitely many models of treewidth $k$,
  then there exists a triple of $k$-graphs $\Gamma=\{G_1,G_2,G_3\}$ such that $\Delta^\Gamma(2\cdot 1^n\cdot 3)$ is a model of $\phi$ for every integer $n$.
\end{proposition}

For the remainder of this section, we prove Proposition~\ref{pro:pump}.
Fix a sentence $\phi$ and an integer $k$.

\begin{definition}
  Let $G$, $G'$ be $k$-graphs.
  We write $G \sim G'$ if and only if for every $k$-graph $H$, we have:
  \begin{equation*}
    G\oplus H\models\phi \iff G'\oplus H\models\phi.
  \end{equation*}
  Of course this depends on $\phi$ and $k$, but they have been fixed for this section.
  Call $\Sigma$ the set of equivalence classes of $\sim$.
\end{definition}

\begin{lemma}[Theorem~13.1.1 from~\cite{df13}]
  \label{lem:pum}
  The set $\Sigma$ of equivalence classes of $\sim$ is finite.
\end{lemma}

\begin{definition}
  Let $G$ denote a $k$-graph with a $k$-tree decomposition $T$.
  For a node $v$ of $T$, let $\mathcal{S}(v)$ denote the largest subtree of $T$ rooted in $v$.
  Call $\mathcal{N}(v)$ the boundaried graph consisting of the subgraph of $G$ spanned by $\bigcup_{u\in\mathcal{S}(v)} B(u)$ and whose set of ports is $B(v)$.
  Finally, call $\mathcal{C}(v)$ the equivalence class of $\mathcal{N}(v)$ for the relation $\sim$.
  When the tree to which $v$ belongs is unclear, we write $\mathcal{S}_T(v)$, $\mathcal{N}_T(v)$ and $\mathcal{C}_T(v)$ to specify it.
\end{definition}

Observe that any tree decomposition of any graph can be viewed as a $\Sigma$-labeled tree:
label each node $v$ with $\mathcal{C}(v)$ instead of a bag.
We say that the $\Sigma$-labeled tree \emph{corresponds to} the tree decomposition.
The following remark is an immediate consequence of the definition of $\sim$.

\begin{remark}
  \label{rk:coh}
  Let $G$ denote a graph with a $k$-tree decomposition $T$, and $v$ the root of $T$.
  Whether $G\models\phi$ or not depends only on $\mathcal{C}_T(v)$.
\end{remark}

A $\Sigma$-labeled tree is \emph{positive} if it corresponds to the decomposition of a model of $\phi$.
A given $\Sigma$-labeled tree might correspond to decompositions of several different graphs,
but Remark~\ref{rk:coh} ensures that they are either all models, or all countermodels.
The next definition applies both to tree decompositions and to $\Sigma$-labeled trees.

\begin{definition}
  \label{dfn:tpack}
  Let $T$ denote a tree, $v$ a node of $T$, and $T'$ another tree.
  Write $T[\mathcal{S}(v)\gets T']$ for the tree obtained by replacing the largest subtree of $T$ rooted in $v$ with $T'$.
  If $v$ is a leaf of $T$, then write $T\oplus_v T'$ for the tree $T[\mathcal{S}(v)\gets T']$.
  When no confusion arises, we may drop the subscript and write $T\oplus T'$.
  
  Now let $\mathcal{T}=\{T_i\}_{i\in I}$ denote a finite family of trees, each with a pointed leaf, and $w$ a finite, nonempty word over alphabet $I$.
  Define $\Lambda^\mathcal{T}$ by induction over the length of $w$:
  \begin{equation*}
    \Lambda^\mathcal{T}(w_1)=T_{w_1},
    \hspace{1cm}
    \Lambda^\mathcal{T}(w_1\dots w_{n})= \Lambda^\mathcal{T}(w_1\dots w_{n-1}) \oplus T_{w_{n}},
  \end{equation*}
  where the pointed leaf of the result is inherited from $T_{w_1}$ or $T_{w_{n}}$, respectively.
  See Figure~\ref{fig:tpack}.
\end{definition}

\begin{figure}
  \newcommand{0.5}{0.5}
  \begin{minipage}{0.48\linewidth}
    \centering
    \begin{tikzpicture}[scale=1.125*0.5]
     
     
      \draw (0,0) rectangle node{$G_{w_{n}}$} ++(5,3);
      \draw[pattern=north east lines] (0.3,2.5) rectangle ++(4.7,0.5);
      \draw (5.5,2.75) node[right]{$P_2(G_{w_{n-1}})=P_1(G_{w_{n}})$};
      \draw (0.3,2.5) rectangle node{$G_{w_{n-1}}$} ++(5,3);
      \draw[pattern=north east lines] (0.3,5) rectangle ++(4.7,0.5);
      \draw (5.5,5.25) node[right]{$P_2(G_{w_{n-2}})=P_1(G_{w_{n-1}})$};
      \draw (0,5) rectangle node{$G_{w_{n-2}}$} ++(5,3);
      \draw (2.5,9.25) node{$\vdots$};
      \draw (0,10.5) rectangle node{$G_{w_2}$} ++(5,3);
      \draw[pattern=north east lines] (0.3,13) rectangle ++(4.7,0.5);
      \draw (5.5,13.25) node[right]{$P_2(G_{w_1})=P_1(G_{w_2})$};
      \draw (0.3,13) rectangle node{$G_{w_1}$} ++(5,3);
    \end{tikzpicture}
    \caption{Illustration of $\Delta$}
    \label{fig:gpack}
  \end{minipage}
  \begin{minipage}{0.48\linewidth}
    \centering
    \begin{tikzpicture}[scale=0.5]
     
      \draw (0,0) -- +(3,3) node{$\bullet$} -- +(6,0) -- cycle;
      \draw (3,1.5) node{$T_{w_{n}}$};
      \draw (0,3) -- +(3,3) node{$\bullet$} -- +(6,0) -- cycle;
      \draw (3,4.5) node{$T_{w_{n-1}}$};
      \draw (0,6) -- +(3,3) -- +(6,0) -- cycle;
      \draw (3,7.5) node{$T_{w_{n-2}}$};
      \draw (3,10.5) node{$\vdots$};
      \draw (0,12) -- +(3,3) node{$\bullet$} -- +(6,0) -- cycle;
      \draw (3,13.5) node{$T_{w_2}$};
      \draw (0,15) -- +(3,3) -- +(6,0) -- cycle;
      \draw (3,16.5) node{$T_{w_1}$};
    \end{tikzpicture}
    \caption{Illustration of $\Lambda$}
    \label{fig:tpack}
  \end{minipage}
\end{figure}

\begin{lemma}
  \label{lem:subst}
  Let $G$ denote a model of $\phi$ with a $k$-tree decomposition $T$,
  and $H$ a graph with a $k$-tree decomposition $U$ whose root is called $u$.
  If $v$ is a node of $T$ such that $\mathcal{C}_T(v)=\mathcal{C}_U(u)$
  then $T[\mathcal{S}(v)\gets U]$, viewed as a $\Sigma$-labeled tree, is positive.
\end{lemma}
\begin{proof}
  Let $T_1$ denote $T\setminus(\mathcal{S}_T(v) - \{v\})$ and $T_2$ denote $\mathcal{S}_T(v)$.
  Call $G_1$ and $G_2$ the subgraphs of $G$ spanned by the nodes in all the bags of $T_1$ and $T_2$, respectively,
  and set $P(G_1)=P(G_2)=B(v)$.
  Observe that $G=G_1\oplus G_2$.
  Make $H$ a boundaried graph by setting $P(H)=B(u)$.
  The relation $\mathcal{C}_U(u)=\mathcal{C}_T(v)$ implies that $\mathcal{N}_U(u)\sim\mathcal{N}_T(v)$, in other terms $H\sim G_2$,
  so by definition of $\sim$ we have $G=G_1\oplus G_2\models\phi\iff G_1\oplus H\models\phi$ (recall that $\oplus$ is symmetric on boundaried graphs).
  Hence $G_1\oplus H$ is a model of $\phi$.
  Observe that $T[\mathcal{S}(v)\gets U]$ corresponds to a tree decomposition of $G_1\oplus H$ and the lemma is proved.
\end{proof}

\begin{remark}
  \label{rmk:pump}
  Let $\Gamma=\{G_i\}_{i\in I}$ a collection of $k$-graphs and $\mathcal{T}=\{T_i\}_{i\in I}$ a collection of $\Sigma$-labeled trees, both indexed by the same finite set $I$.
  Suppose that for every $i$, the tree $T_i$ corresponds to a decomposition of $G_i$ such that the root's bag is $P_1(G_i)$ and there is a leaf whose bag is $P_2(G_i)$.
  Make that leaf the pointed leaf of $T_i$.
  Then, for every nonempty word $w$ over alphabet $I$, 
  the tree $\Lambda^\mathcal{T}(w)$ corresponds to a decomposition of $\Delta^\Gamma(w)$.
  As an illustration of this remark,
  we could say that the bags of the bold nodes in Figure~\ref{fig:tpack} are the nodes in hatched areas in Figure~\ref{fig:gpack}.
\end{remark}

Recall that in a digraph (and in particular in a tree),
the degree of a node is the sum of its in-degree and its out-degree.

\begin{lemma}
  \label{lem:tdeg}
  If a graph $G$ has a $k$-tree decomposition with $n$ nodes,
  then it has a $k$-tree decomposition of degree~$3$ with at least $n$ nodes.
\end{lemma}
\begin{proof}
  Split any node with more than $3$ neighbors in the tree into a chain of nodes.
\end{proof}



\begin{proof}[Proof of Proposition~\ref{pro:pump}]
  The sentence $\phi$ has models with $k$-tree decompositions having arbitrarily high numbers of nodes.
  By Lemma~\ref{lem:tdeg}, there is a sequence $(M_i)_{i\in\mathbb{N}}$ of models and
  a sequence $(D_i)_{i\in\mathbb{N}}$ of respective $k$-tree decompositions,
  such that $D_i$ has depth at least $i$.
  View the $D_i$'s as $\Sigma$-labeled trees.
  By Lemma~\ref{lem:pum} the set $\Sigma$ of values for $\mathcal{C}(\cdot)$ is finite;
  let $n=|\Sigma|+1$, so that any $\Sigma$-labeled path of length $n$ contains two nodes with the same label.
  In particular, the model $M_n$ has a tree decomposition $D_n$ containing a path of length $n$,
  thus two nodes $v$ and $v'$ such that $\mathcal{C}(v)=\mathcal{C}(v')$.
  Suppose without loss of generality that $v$ has lesser depth than $v'$ and let (see Figure~\ref{fig:pump}):
  \begin{equation*}
    T_1=\mathcal{S}(v)\setminus(\mathcal{S}(v') - \{v'\}),
    \hspace{1cm}
    T_2=D_n\setminus(\mathcal{S}(v) - \{v\}),
    \hspace{1cm}
    T_3=\mathcal{S}(v').
  \end{equation*}
  Define the graphs $G_1$, $G_2$ and $G_3$ as the induced subgraphs of $M_n$ spanned by all the bags of $T_1$, $T_2$ and $T_3$, respectively.
  Set $P_2(G_2)=P_1(G_1)=B(v)$ and $P_2(G_1)=P_1(G_3)=B(v')$;
  choose arbitrarily $P_1(G_2)$ and $P_2(G_3)$.
  Let $\Gamma=(G_1,G_2,G_3)$ and $\mathcal{T}=(T_1,T_2,T_3)$, so that by Remark~\ref{rmk:pump},
  the tree $\Lambda^\mathcal{T}(2\cdot 1^m\cdot 3)$ corresponds to a decomposition of $\Delta^\Gamma(2\cdot 1^m\cdot 3)$ for every $m$.
  Since $\mathcal{C}(v)=\mathcal{C}(v')$, Lemma~\ref{lem:subst} implies that for every integer $m$,
  the tree $\Lambda^\mathcal{T}(2\cdot 1^m\cdot 3)$ is positive.
  Therefore $\Delta^\Gamma(2\cdot 1^m\cdot 3)$ is a model of $\phi$.
\end{proof}

\begin{figure}
  \centering
  \begin{tikzpicture}[scale=.7,baseline]
    \foreach \s [count=\i] in {0,1.5,3} {
      \coordinate (a\i) at ($(0,0)  +(0,-\s)$);
      \coordinate (b\i) at ($(2,3)  +(0,-\s)$);
      \coordinate (c\i) at ($(4,0)  +(0,-\s)$);
      \coordinate (d\i) at ($(3,0)  +(0,-\s)$);
      \coordinate (e\i) at ($(2,1.5)+(0,-\s)$);
      \coordinate (f\i) at ($(1,0)  +(0,-\s)$);
    }
    \foreach \i in {1,2} {
      \draw (a\i)--(b\i)--(c\i)--(d\i)--(e\i)--(f\i)--cycle;
    }
    \draw (a3)--(b3)--(c3)--cycle;
    \draw (b1)++(0,-.75) node{$T_2$};
    \draw (b2) node{$\bullet$} node[right]{$v$}  ++(0,-.75) node{$T_1$};
    \draw (b3) node{$\bullet$} node[right]{$v'$} ++(0,-1.5) node{$T_3$};
    \draw[decorate,decoration={brace,mirror}] (-.5,3) -- node[left]{$D_n$} (-.5,-3);
  \end{tikzpicture}
  \hspace{.5cm}
  $\to$
  \hspace{.5cm}
  \begin{tikzpicture}[scale=.7,baseline]
    \foreach \s [count=\i] in {0,1.5,...,6} {
      \coordinate (a\i) at ($(0,0)  +(0,-\s)$);
      \coordinate (b\i) at ($(2,3)  +(0,-\s)$);
      \coordinate (c\i) at ($(4,0)  +(0,-\s)$);
      \coordinate (d\i) at ($(3,0)  +(0,-\s)$);
      \coordinate (e\i) at ($(2,1.5)+(0,-\s)$);
      \coordinate (f\i) at ($(1,0)  +(0,-\s)$);
    }
    \foreach \i in {1,...,4} {
      \draw (a\i)--(b\i)--(c\i)--(d\i)--(e\i)--(f\i)--cycle;
    }
    \draw (a5)--(b5)--(c5)--cycle;
    \draw (b1)++(0,-.75) node{$T_2$};
    \foreach \i in {2,...,4} {
      \draw (b\i)++(0,-.75) node{$T_1$};
    }
    \draw (b5)++(0,-.75) node{$T_3$};
  \end{tikzpicture}
  \caption{Proof of Proposition~\ref{pro:pump}.}
  \label{fig:pump}
\end{figure}

\begin{remark}
  Note that in Proposition~\ref{pro:pump}, graphs $G_1$, $G_2$ and $G_3$ are constant so the family of graphs of the form ${\Delta^\Gamma(2\cdot 1^n\cdot 3)}$ for ${n\geq 1}$ is of bounded pathwidth.
  Therefore it holds that an MSO formula has infinitely many models models among bounded treewidth graphs if and only if it does among bounded pathwidth ones.
\end{remark}

\section{A reduction from \textsc{$\phi$-Dynamics} to SAT}
\label{sec:sat}

In all this section, for any biboundaried graph $G$, assume that $V(G)=\{0,\dots,|G|-1\}$
and for a node $u$ of $G$, write $G(u)$ the set $\{v:(u,v)\in E(G)\}$.
Thus, $P_1(G)$, $P_2(G)$ and $G(u)$ are all subsets of $\{0,\dots,|G|-1\}$.

\begin{proposition}
  \label{pro:sat}
  Fix an MSO sentence $\phi$.
  Let $k$ be an integer and $\Gamma=\{G_0, G_1, G_2, G_3\}$ four $k$-graphs such that:
  \begin{enumerate}[label={(\roman*)}]
  \item\label{itm:eqsz} $|G_0|=|G_1|$;
  \item\label{itm:cap} $P_1(G_0)\cap P_2(G_0)=P_1(G_1)\cap P_2(G_1)$; and
  \item\label{itm:img} for every $p$ in $P_1(G_0)\cap P_2(G_0)$, we have $G_0(p)=G_1(p)$.
  \end{enumerate}
  Suppose that, for every word $w$ over alphabet $\{0,1\}$, we have $\Delta^\Gamma(2\cdot w \cdot 3)\models\phi$ if and only if $w$ contains letter $0$.
  Then $\phi$-dynamics is {\ensuremath{\mathsf{NP}}}-hard, even if we restrict to inputs with bounded non-determinism.
\end{proposition}

\begin{definition}
  If $S$ is an instance of SAT with $s$ variables,
  then $\overline{S}$ is the word of length $2^s$ such that $\overline{S}_i$ is $1$ if $S(i)$ is false, and $0$ if $S(i)$ is true
  (viewing the binary expansion of $i$ as a Boolean assignment for $S$).
\end{definition}

\begin{lemma}
  \label{lem:sat}
  Let $S$ be an instance of SAT with $s$ variables,
  $k$ an integer and $\Gamma=\{G_0, G_1, G_2, G_3\}$ four $k$-graphs satisfying Conditions~\ref{itm:eqsz}--\ref{itm:img} of Proposition~\ref{pro:sat}.
  Then, there is an integer $c$ and an automata network $F$ such that
  \begin{equation*}
    \TG{F}=\Delta^\Gamma(2\cdot\overline{S}\cdot 1^c \cdot3), 
  \end{equation*}
  that can be computed in polynomial time given $S$ (the $G_i$ are considered constant).
\end{lemma}
\begin{proof}
  The proof is in two steps.
  The first step only gives the configuration space and the global transition relation of $F$.
  It does not explain how these transitions are realized by an automata network,
  nor how Boolean circuits for that network may be produced in polynomial time: that is deferred to the second step.

  \paragraph*{First step.}
  For now, let $c$ be an arbitrary positive or null integer.
  (We will need to perform some form of padding in the second step and $c$ will be that amount of padding;
  it remains unspecified in the first step.)
  If $G$ is a biboundaried graph, define:
  \begin{equation*}
    P'_1(G)=P_1(G)\setminus P_2(G),\hspace{1cm}
    P'_2(G)=P_2(G)\setminus P_1(G),\hspace{1cm}
    P'_3(G)=P_1(G)\cap P_2(G).
  \end{equation*}
  The rationale is that we will need to handle ports that are in $P_1(G) \cap P_2(G)$ as a special case later.
  By Conditions~\ref{itm:eqsz} and~\ref{itm:cap}, we have $|P'_1(G_1)|=|P'_1(G_0)|=|P'_2(G_1)|=|P'_2(G_0)|$;
  call $k'$ that quantity.
  We also have $|P'_3(G_1)|=|P'_3(G_0)|$; call $k''$ that quantity.
  Observe that $k=k'+k''$.

  Recall that for any $k$-graph $G$, we assume that $V(G)=\{0,\dots,|G|-1\}$.
  Intuitively, we want to arrange things so that $P_1(G)$ is at the beginning of the interval (i.e., $\{0,\dots,k-1\}$)
  and $P_2(G)$ at the end of the interval (i.e., $\{|G|-k,\dots,|G|-1\}$), so that it becomes easy to merge vertices when computing a gluing ($\oplus$) operation---see Figure~\ref{fig:sat}.
  Things are unfortunately not that simple: we need to account for the possibility that $P_1(G)\cap P_2(G)\neq\emptyset$.
  Thus we will put $P'_1$ at the beginning, $P'_3$ at the end, and $P'_2$ just before $P'_3$.
  The only exception is in $G_3$: we put $P'_3$ just after $P'_1$, for reasons that we will explain later on.
  Formally speaking, for $i=0,1,2$, assume without loss of generality that:
  \begin{align*}
    P'_1(G_i)&=(0,\dots,k'-1),&
    P'_2(G_i)&=(|G_i|-k,\dots,|G_i|-k''-1),&
    P'_3(G_i)&=(|G_i|-k'',\dots,|G_i|-1),\\
    P'_1(G_3)&=(0,\dots,k'-1),&
    P'_2(G_3)&=(|G_3|-k',\dots,|G_3|-1),&
    P'_3(G_3)&=(k',\dots,k-1).
  \end{align*}
  Define the quantities:
  \begin{equation*}
    n_1=|G_1|-k=|G_0|-k,
    \hspace{1cm}
    n_2=|G_2|-k,
    \hspace{1cm}
    n_3=|G_3|.
  \end{equation*}
  The configuration space of $F$ is $\{0,\dots,n_2+(2^s+c)\cdot n_1+n_3-1\}$: see Figure~\ref{fig:sat} for a picture of its organization.
  The initial segment is the (unique) copy of $G_2$, followed by $2^s+c$ copies of $G_0$ or $G_1$, followed by the (unique) copy of $G_3$.
  Those copies overlap to account for the merged vertices between all those graphs.
  Let $\ell=2^s+c-1$ be the index of the last copy of $G_0$ or $G_1$.
  For $q$ in $\{-1,0,\dots,2^s+c\}$, define (see the following paragraph for intuition):
  \begin{align}
    \label{eq:dcase01}
    \delta^q_0(r)=\delta^q_1(r)&=
    \begin{cases}
      n_2+q\cdot n_1+r &\text{ if } r\in\{0,\dots,|G_1|-k''-1\},\\
      n_2+\ell\cdot n_1+r &\text{ if } r\in\{|G_1|-k'',\dots,|G_1|-1\};
    \end{cases}\\
    \label{eq:dcase2}
    \delta^q_2(r)&=
    \begin{cases}
      r &\text{ if } r\in\{0,\dots,|G_2|-k''-1\},\\
      \delta^\ell_1(r)+|G_1|-|G_2|&\text{ if } r\in\{|G_2|-k'',\dots,|G_2|-1\};\\
    \end{cases}\\
    \label{eq:dcase3}
    \delta^q_3(r)&=n_2+(2^s+c)\cdot n_1+r.
  \end{align}
  The functions $\delta$ map integers to integers, but we implicitly extend them to sets of integers, elementwise.
  Intuitively, $\delta^q_j(r)$ refers to the $r^\text{\scriptsize th}$ node of a copy of $G_j$ in Figure~\ref{fig:sat}, i.e., in the configuration space of $F$.
  There is only one copy of $G_2$ and one of $G_3$, so if $j=2,3$, this is unambiguous.
  But there are many (precisely $2^s+c$) copies of $G_0$ and $G_1$, and whether a given graph is $G_0$ or $G_1$ will change according to $S$;
  therefore, the superscript $q$ is used to specify which copy of $G_0$ (or $G_1$) we are targeting.
  It will be convenient to write $\delta^q_2$ and $\delta^q_3$ even though they do not depend on $q$.
  
  Now the only difficulty resides in the $k''$ ports common to all occurrences of $G_0$ and $G_1$---%
  which are also common to the copy of $G_2$ and the copy of $G_3$, by construction.
  They are ``physically'' located after the last copy of $G_0$ or $G_1$, which has index $\ell$.
  There is a special case in Equations~\eqref{eq:dcase01} and~\eqref{eq:dcase2} to redirect any edges going into these nodes to the proper location.
  The graph $G_3$ is organized so that elements of $P'_3(G_3)$ are already at the right place.
  The edges going out of those nodes are handled later on.
  
  We are now ready  to give the global transition function $F$, from the configuration space to itself.
  Recall that $F$ is nondeterministic, so the value of $F(x)$ is a set.
  \begin{itemize}
  \item If $x<n_2$, then set:
    \begin{equation}
      \label{eq:fcase2}
      F(x)=(\delta^0_2\circ G_2)(x).
    \end{equation}
  \item If $x-n_2<(2^s+c)\cdot n_1$, then by Euclidean division let $q$, $r$ be such that $x-n_2=q\cdot n_1+r$, with $r \in \{0,\dots,n_1-1\}$.
    Let $i$ and $j$ denote $\overline{S}(q-1)$ and $\overline{S}(q)$ respectively.
    However if $q=0$, then set $i=2$ instead;
    if $q-1$ (respectively $q$) is $2^s$ or higher, then set $i$ (respectively $j$) to $1$ instead.
    Set:
    \begin{equation}
      \label{eq:fcase01}
      F(x)=
      \begin{cases}
        (\delta^q_j\circ G_j)(r) \sqcup (\delta^{q-1}_i\circ G_i)(r+n_i) &\text{ if } r\in\{0,\dots,k'-1\},\\
        (\delta^q_j\circ G_j)(r) &\text{ otherwise.}
      \end{cases}
    \end{equation}
  \item Otherwise, $n_2+(2^s+c)\cdot n_1\leq x$, so let $q=2^s+c$ and $r=x-(n_2+(2^s+c)\cdot n_1)$.
    Let $i=\overline{S}(2^s-1)$ if $c=0$ and $i=1$ otherwise, and set:
    \begin{equation}
      \label{eq:fcase3}
      F(x)=
      \begin{cases}
        (\delta^0_3\circ G_3)(r)\sqcup(\delta^{q-1}_i\circ G_i)(r+n_1)&\text{ if }0\leq r<k',\\
        (\delta^0_3\circ G_3)(r)\sqcup(\delta^0_2\circ G_2)(r+n_2) \bigsqcup_{t=0}^\ell(\delta^t_1\circ G_1)(r+n_1)&\text{ if }k'\leq r<k,\\
        (\delta^0_3\circ G_3)(r) &\text{ otherwise.}
      \end{cases}
    \end{equation}
  \end{itemize}
  Observe that $\TG{F}$ is, by construction, $\Delta^\Gamma(2\cdot\overline{S}\cdot 1^c\cdot 3)$.
  Assume, for the sake of the discussion, that $S(0)$ evaluates to true and $S(1)$ to false, so the first two graphs after $G_2$ are $G_0$, then $G_1$.
  Those two graphs share $k'$ vertices that they do not share with any other $G_j$ in the construction.
  Those vertices are ``physically'' located at nodes $\{0,\dots,k'-1\}$ of the copy of $G_1$.
  The edges from $G_0$ going into those shared nodes naturally point correctly,
  because the last $k'$ nodes of $G_0$ are identified with the first $k'$ nodes of $G_1$
  (both are, by definition, encoded by $n_2+n_1+\{0,\dots,k'-1\}$ in the global dynamics---see the overlaps in Figure~\ref{fig:sat}).
  The edges going out of those shared nodes into $G_0$ are realized by the first case in Equation~\eqref{eq:fcase01}.
  The same reasoning goes for $S(1)$ and $S(2)$, and so on.

  As explained previously, there are $k''$ nodes that are shared by all the copies of $G_0,G_1,G_2,G_3$ in the dynamics.
  The edges going into those nodes were handled in the definition of $\delta^q_j$;
  the edges going out of those nodes are handled by the second case of Equation~\eqref{eq:fcase3}.
  That case assumes that all copies of $G_0$ and $G_1$ in the dynamics are in fact copies of $G_1$;
  this yields the desired results by Condition~\ref{itm:img}.

  \begin{figure}
    \centering
    \begin{tikzpicture}[xscale=.9,yscale=.7]
      \fill[gray!40!white] (14.2,0) rectangle node[black]{$k''$} ++(0.8,1.25);

      \newcommand{0.1}{0.1}
      \draw[->,>=latex] (0,0) -- (17,0);
      \draw (0,-0.1) -- (0,+0.1);
      \foreach \x in {0.2,0.4,...,16.8} {
        \draw (\x,0) -- (\x,0.1);
      }
      \newcommand{\gr}[4]{
        \draw[decorate,decoration={brace}] (#1,#2) -- node[above]{#3} ++(#4,0);
        \draw[dashed] (#1,#2) -- (#1,0);
        \draw[dashed] (#1+#4,#2) -- (#1+#4,0);
      }
      \gr{0}{0.8}{$G_2$}{3.2};
      \gr{2.4}{1.2}{$G_0$}{3};
      \gr{4.8}{0.8}{$G_1$}{3};
      \gr{7.2}{1.2}{$G_0$}{3};
      \draw (10.7,0.5) node{$\dots$};
      \gr{11.2}{0.8}{$G_1$}{3};
      \gr{13.6}{1.2}{$G_3$}{3.2};

      \draw[<-] (0.1,-0.1) -- ++(0,-0.5) node[below]{$0$};
      \draw[<-] (2.5,-0.1) -- ++(0,-0.5) node[below]{$n_2$};
      \draw[<-] (3.3,-0.1) -- ++(0,-1.5) node[below]{$n_2+k'=|G_2|-k''$};
      \draw[<-] (4.9,-0.1) -- ++(0,-0.5) node[below]{$n_2+n_1$};
      \draw[<-] (5.5,-0.1) -- ++(0,-2.5) node[below]{$n_2+n_1+k'=n_2+|G_0|-k''$};
      \draw[<-] (7.3,-0.1) -- ++(0,-0.5) node[below]{$n_2+2n_1\,~$};
      \draw[<-] (7.925,-0.1) -- ++(0,-1.5) node[below]{$n_2+n_1+|G_1|-k''$};
      \draw[<-] (11.3,-0.1) -- ++(0,-0.5) node[below]{$n_2+(2^s+c-1)\cdot n_1$};
      \draw[<-] (13.7,-0.1) -- ++(0,-1.5) node[below]{$n_2+(2^s+c)\cdot n_1$};
    \end{tikzpicture}
    \caption{Proof of Lemma~\ref{lem:sat}, a representation of $\{0,\dots,n_2+(2^s+c)\cdot n_1+n_3-1\}$ as the configuration space of $F$.
      The gray area ($k''$) is actually common to all the graphs.}
    \label{fig:sat}
  \end{figure}

  \paragraph*{Second step.}
  We have a configuration space and a transition relation; we want an automata network that realizes them.
  First, we determine (in polynomial time) the number of automata of $F$ and the alphabet of each automaton.
  This process fixes the value of $c$, which does no harm, because the previous step worked for arbitrary values of $c$.
  
  Let $p=n_2+n_3$ and $d=\gcd(p,n_1)$; write $p=p'\cdot d$ and $n_1=n'\cdot d$ for coprime integers $p'$, $n'$.
  Find an integer $t$ such that $p\leq 2^t$ and $\gcd(s+t,\varphi(n'))=1$, where $\varphi$ denotes Euler's totient and $s$ is the number of Boolean variables of $S$.
  To do so, let $t'=s/\gcd(s,\varphi(n'))$, so that $t'$ and $\varphi(n')$ have no common prime factors.
  Then let $t''$ denote a power of $t'$ that exceeds $s+\lceil\log_2 p\rceil$ (compute it by successive squarings).
  Finally, take $t=t''-s$.

  Since $\gcd(p',n')=1$, we can use Algorithm~17.1 from~\cite{s12}
  to find an integer $e\geq 1$ such that $e^{s+t}\equiv p'\mod n'$.
  For the rest of the proof, assume that $e\geq 2$: indeed, if $e=1$, then $p'\equiv 1\mod n'$,
  so by Euler's formula we can choose $e=p'^{\varphi(n')}$ instead.
  Since Algorithm~17.1 from~\cite{s12} runs in polynomial time and $p'$, $n'$ are constants, we can find $e$ and $t$ in polynomial time.
  (Recall that $s$ is the number of variables of $S$, our input, so we can consider that $s$ is given in unary.)

  The automata network $F$ has one node over alphabet $\{0,\dots,d-1\}$ and $s+t$ nodes over alphabet $\{0,\dots,e-1\}$.
  Its configuration space has $d\cdot e^{s+t}$ elements.
  Since $2\leq e$, we have $2^s\leq e^s$ and $p\leq 2^t\leq e^t$;
  moreover we have $e^{s+t}\equiv p'\mod n'$, so there is an integer $c\geq 0$ such that $d\cdot e^{s+t}=p+(2^s+c)\cdot n$.

  Now that we have the right number of configurations, it is easy to produce in polynomial time the Boolean circuits for $F$:
  they read the current configuration as an integer and apply the rules from the first step of this proof.
  The $G_i$ are considered constant, and the only part that depends on $S$ merely evaluates $S$.
  Moreover, each configuration requires at most two evaluations of $S$ to compute the set of successors (in Equation~\ref{eq:fcase01},
  for the values of $i$ and $j$).
  This concludes the proof.
\end{proof}

\begin{proof}[Proof of Proposition~\ref{pro:sat}]
  Immediate consequence of Lemma~\ref{lem:sat}:
  given an instance $S$ of SAT, compute in polynomial time the corresponding automata network $F$, and ask $\phi$-dynamics on that $F$.
  Moreover, the transition graphs of such automata networks are all of the form ${\Delta^\Gamma(w)}$ for a fixed set of finite graphs $\Gamma$ so they have a bounded degree, meaning that the constructed automata networks have bounded non-determinism.
\end{proof}

\begin{proof}[Proof of Theorem~\ref{thm:main}]
  Let $\phi$ denote an arborescent MSO sentence with $m$ quantifiers.
  By Proposition~\ref{pro:saturating}, the graph $\Omega_m$ is either forbidden or sufficient for $\phi$.
  Assume that $\Omega_m$ is forbidden for $\phi$ and prove that $\phi$-dynamics is {\ensuremath{\mathsf{NP}}}-hard.
  (If it was sufficient, then consider $\neg\phi$ instead---this would yield that $\phi$-dynamics is {\ensuremath{\mathsf{coNP}}}-hard.)
  By Proposition~\ref{pro:pump},
  there exist a triple of graphs $\Gamma=(G_1,G_2,G_3)$ such that $\Delta^\Gamma(2\cdot 1^n\cdot 3)$ is a model of $\phi$ for every integer $n$.
  Let $H$ denote the subgraph of $G_1$ spanned by:
  \begin{equation*}
    \left[P_1(G_1)\cap P_2(G_1)\right]
    \;\bigcup\;
    \{j : \exists i \in P_1(G_1)\cap P_2(G_1), (i,j)\in E(G_1)\}
  \end{equation*}
  and $G_0=H\sqcup \Omega_m$ (see Figure~\ref{fig:G0}).
  Let $G'_1=\bigoplus_{i=1}^n G_1$, where $n$ is the smallest integer such that $|G'_1|\geq |G_0|$.
  Finally, let $G'_0$ denote $G_0$ with enough isolated nodes added so that $|G'_0|=|G'_1|$.
  It is possible to reorder the nodes of $G'_0, G'_1$ and add ports so that the quadruple $\Gamma'=(G'_0, G'_1, G_2, G_3)$ satisfies all the conditions of Proposition~\ref{pro:sat}.
  This concludes the proof of the theorem.
\end{proof}

\begin{figure}
  \centering
  \begin{tikzpicture}
    \draw[dashed] (0,0) rectangle ++(8,3);
    \draw (0,2.75) node[right]{($H$, copied from $G_1$)};
    \foreach \i in {1,...,7} {
      \node (a\i) at (\i,1) {$\bullet$};
      \node (b\i) at (\i+.25,2) {$\bullet$};
      \node (c\i) at (\i,2)    {$\bullet$};
      \node (d\i) at (\i-.25,2) {$\bullet$};
      \draw[->,>=latex] (a\i) -- (b\i);
      \draw[->,>=latex] (a\i) -- (c\i);
      \draw[->,>=latex] (a\i) -- (d\i);
    }
    \draw[decorate,decoration={brace,mirror}] (a1.south) -- node[below]{$P_1(G_1)\cap P_2(G_1)$} (a7.south);
    \draw (9,0) rectangle node{$\Omega_m$} ++(3,3);
  \end{tikzpicture}
  \caption{Representation of $G_0$ in the proof of Theorem~\ref{thm:main}.}
  \label{fig:G0}
\end{figure}

\begin{remark}
  Note that the constructed automata networks are such that all nodes except one have the same alphabet.
  The proof of Lemma~\ref{lem:sat} is as close as we could get to a proof working for automata networks with constant uniform alphabet, which is the most usual setting in the literature.
  We have no idea how to close the gap to fit this setting.
\end{remark}

\section{Nonarborescent formulae}
\label{sec:bad}

In this section, we explore what happens when the \emph{arborescence} condition in Theorem~\ref{thm:main} is negated.

First, if $\phi$ is an MSO sentence with finitely many models or with finitely many countermodels, then it is not arborescent.
But in this case, we can test $\phi$ in constant time.
Indeed, if $\phi$ has finitely many models, then there are finitely many automata networks whose dynamics satisfy $\phi$
(because we assume that Boolean circuits are never bigger than their transition tables).
So testing $\phi$ amounts to testing whether the input belongs to a fixed list, which can be done in constant time:
any input larger than the largest element of the list can immediately be rejected without further computation.
We call such sentences \textbf{trivial}.

More interestingly, the question ``is $\TG{F}$ a clique?'' is expressible in first order, hence in MSO,
but is both nonarborescent and nontrivial.
It is easy to show that this question is {\ensuremath{\mathsf{coNP}}}-hard: given an instance $S$ of SAT with $s$ variables,
make a network with $s$ Boolean automata that views its own configuration as an assignement for $S$ and evaluates it.
If it finds ``false'', then each automaton can choose nondeterministically either to change state or to remain in the same state.
If it finds ``true'', then all automata are required to stay in the same state.
The transition graph of that network is a clique if and only if all assignments for $S$ evaluate to false.
Producing Boolean circuits which evaluate a given instance of SAT is easily done in polynomial time,
which concludes the reduction.

It is tempting to conjecture that for every nontrivial MSO formula $\phi$, the problem \textsc{$\phi$-Dynamics} is either {\ensuremath{\mathsf{NP}}}- or {\ensuremath{\mathsf{coNP}}}-hard.
The next theorem shows that this conjecture is unlikely to hold.

\begin{definition}[Definition~1 from~\cite{fs17}]
  A set $M$ of integers is \textbf{robust} if and only if:
  \begin{equation*}
    \forall k, \exists \ell \geq 2: \{\ell,\ell+1,\dots,\ell^k\} \subset M.
  \end{equation*}
  This implies that $M$ is infinite.
\end{definition}

We denote by UNSAT the complement of SAT (\textit{i.e.} CNF formulae that are not satisfiable).

\begin{theorem}
  \label{thm:bad}
  There is a nontrivial first-order sentence $\psi$ such that, if either SAT or UNSAT reduces to \textsc{$\psi$-Dynamics},
  then there is a polynomial-time algorithm solving SAT for a robust set of sizes of instances.
\end{theorem}

According to Proposition~8 and Theorem~12 of~\cite{fs17}, our Theorem~\ref{thm:bad} implies:

\begin{corollary}
  Let $\psi$ be given by Theorem~\ref{thm:bad}.
  If either SAT or UNSAT reduces to \textsc{$\psi$-Dynamics},
  then any problem in the polynomial hierarchy can be solved in polynomial time on a robust set of sizes of instances.
\end{corollary}

The rest of this section is a proof of Theorem~\ref{thm:bad}.
For now, let $\psi$ be an arbitrary first-order sentence,
and $f$ a polynomial reduction from either SAT or UNSAT to \textsc{$\psi$-Dynamics}.

\begin{definition}
  Let $P$ be a polynomial and $n$ a positive integer.
  The reduction $f$ is \textbf{$P$-meager in $n$} if and only if
  for every instance $S$ of SAT with size $n$, we have:
  \begin{equation*}
    |f(S)| \leq \log P(n).
  \end{equation*}
  The set of values in which $f$ is $P$-meager is called the \textbf{$P$-meagerness set} of $f$.
\end{definition}

Let $P$ denote a polynomial.
If $f$ is $P$-meager in some integer $n$,
then all instances of SAT with size $n$ are mapped to networks whose transition graphs have $O(P(n))$ vertices.
Indeed, the transition graph is exponentially large in the network description.
Besides, we can test $\psi$ on a graph $G$ in time polynomial in $|G|$,
the degree of the polynomial being the quantifier rank of $\psi$
(recall that $\psi$ is a first-order sentence).
Therefore:

\begin{lemma}
  \label{lem:meagersat}
  Assume that $f$ is a reduction as before and let $P$ be a polynomial.
  There is a polynomial-time algorithm that solves SAT on all instance sizes that are in the $P$-meagerness set of $f$.
\end{lemma}
\begin{proof}
  Given an instance $S$ of SAT with size $n$, compute the network $f(S)$ in polynomial time;
  call $G$ its transition graph.
  We can compute the size of $G$ from $f(S)$ in polynomial time,
  because we have the list of nodes and the state set of each node.
  If $|G| > P(n)$, then return whatever answer: $f$ is not $P$-meager in $n$ anyway.
  Otherwise compute $G$ itself, which can be done in polynomial time since $|G| \leq P(n)$,
  and evaluate $\psi$ on $G$, which can also be done in polynomial time (the final answer is negated if reduction $f$ is from UNSAT instead of SAT).
\end{proof}

\begin{lemma}
  \label{lem:meagerenum}
  Let $f$ be a reduction as before and $P$ be a polynomial.
  If $f$ has a nonrobust $P$-meagerness set then, for every integer $d\geq 1$, either:
  \begin{enumerate}[label=(\roman*)]
    \item $f$ produces a model of $\psi$ whose size is not in $\mathbb{N}^{(d)}=\{n^d : n\in\mathbb{N}\}$; or
  \item there exists an increasing primitive-recursive sequence $\mu$ such that $\mu(n)^d$ is the size of a model of $\psi$ for each $n$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  By hypothesis there is an integer $k$ such that, for every $\ell \geq 2$,
  there is at least one value among $\ell,\ell+1,\dots,\ell^k$ in which $f$ is not $P$-meager.
  Observe that if $P'$ is the polynomial giving the execution time of $f$,
  then $f$ produces networks whose transition graphs have size at most $2^{P'(n)}$
  with $n$ the size of the SAT or UNSAT instance.
  Let $t:\mathbb{N}\to\mathbb{N}$ be a primitive recursive function such that, for every $n$:
  \begin{equation}
    \label{eq:t}
    t(n+1) > \max\{2^{P'(t(n))}, t(n)^k\}.
  \end{equation}
  Moreover since the meagerness set of $f$ is nonrobust,
  we can additionally choose $t$ such that $f$ is not $P$-meager in $t(n)$, for every $n$.
  (Starting from a function $t$ that satisfies Equation~\eqref{eq:t}, given $n$,
  it is possible to enumerate all values $t(n),t(n)+1,\dots,t(n)^k$ and to find the one for which $f$ is not $P$-meager.
  That computation can be done in a primitive recursive fashion.)

  For every $n$, let us pass to $f$ a positive instance of SAT with size $t(n)$
  (or a negative instance if reduction $f$ is from UNSAT instead of SAT);
  the result is a sequence of automata networks, $(\alpha(n))_{n\in\mathbb{N}}$.
  This sequence can be made primitive recursive because $t$ and $f$ are.
  Call $\beta(n)$ the transition graph of $\alpha(n)$;
  since $f$ is a reduction and we passed positive instances of SAT to it,
  the graph $\beta(n)$ is a model of $\psi$.
  By non-$P$-meagerness of $f$ in $t(n)$, we can furthermore compute
  the instances of SAT such that:
  \begin{equation*}
    P(t(n))\leq |\beta(n)|,
  \end{equation*}
  in a primitive recursive fashion
  (simply by enumerating propositional formulae of size $t(n)$).
  Also, considering that $P'$ is the running time of $f$,
  that a transition graph is at most exponential in the size of the network,
  and Equation~\eqref{eq:t}, we have:
  \begin{equation*}
    |\beta(n)|  \leq 2^{P'(t(n))} < t(n+1).
  \end{equation*}
  Since $P(t(n)) \leq |\beta(n)| < P(t(n+1))$, the sequence $|\beta(n)|$ is increasing in $n$.

  Moreover for every $d\geq 1$, there is an $n_0$ such that for every ${n\geq n_0}$,
  we have $|\beta(n+2)|^{1/d} > |\beta(n)|^{1/d}$ (as $|\beta(n+2)|> 2^{P'(|\beta(n)|)}$).
  If ${|\beta(n)|^{1/d}}$ is not an integer for some $n$ then the reduction $f$ produces a model of $\psi$ whose size is not in ${\mathbb{N}^{(d)}}$ and the lemma follows.
  Otherwise, we define the map $\mu:\mathbb{N}\to\mathbb{N}$ by $\mu(n) = |\beta(2(n+n_0))|^{1/d}$;
  by the previous inequality $\mu$ is an increasing map.
  Finally, since $\alpha(n)$ is primitive recursive in $n$, so is $\beta(n)$ and so is $\mu(n)$.
  The lemma follows because by construction ${\mu(n)^d}$ is always the size of a model of $\phi$.
\end{proof}

\begin{definition}
  The \textbf{spectrum} of $\psi$ is the set of sizes of models of $\psi$.
  In symbols:
  \begin{equation*}
    \mathrm{Spec}(\psi) = \{|G|:G\models\psi\}.
  \end{equation*}
  See~\cite{djmm12} for a survey about this notion.

  A function $h:\mathbb{N}\to\mathbb{N}$ is \textbf{time-constructible} if and only if
  there is a Turing machine that, for every $n$, halts in exatly $h(n)$ steps on input $n$ written in binary.
\end{definition}

\begin{lemma}
  \label{lem:specim}
  For every time-constructible function $h$,
  there exist a first-order sentence $\psi_h$ and an integer $d$ such that $\mathrm{Spec}(\psi_h)=\mathrm{Im}(h)^{(d)}$, where
  $\mathrm{Im}(h)^{(d)} = \{n^d : n \in \mathrm{Im}(h)\}$.
\end{lemma}
\begin{proof}
  By~\cite[Theorem 4.5]{js75} and~\cite[Theorem 3]{f75},
  we just have to prove that $\mathrm{Im}(h)$ is a {\ensuremath{\mathsf{NEXPTIME}}}{} language.
  Given $n$, the algorithm guesses a word $u$ of length at most $n$,
  runs $h$ on input $u$ and checks that it halts in $n$ steps exactly.
  If $n\in\mathrm{Im}(h)$ then there is $u$ such that $h(u)=n$ and $|u|\leq n$ 
  because the machine cannot read more than $n$ input symbols within $n$ steps.
\end{proof}

\begin{lemma}
  \label{lem:diag}
  There is a first-order sentence $\psi$ and an integer $d$ such that, for every increasing primitive-recursive function $R$, we have:
  \begin{equation}
    \label{eq:specpsi}
    \mathrm{Im}(R)^{(d)} \not\subseteq \mathrm{Spec}(\psi)\subseteq\mathbb{N}^{(d)}.
  \end{equation}
\end{lemma}
\begin{proof}
  Let $(R_n)_{n\in\mathbb{N}}$ be a computable enumeration of increasing primitive-recursive functions.
  (To construct one, start from a computable enumeration of primitive-recursive functions $(R'_n)_{n\in\mathbb{N}}$
  and change $R'_n$ into $R_n$ as follows: $R_n:i\mapsto \max\{R_n(i-1)+1, R'_n(i)\}$.
  This transformation is computable and leaves increasing functions unchanged, so it hits all of them.)
  
  For every integer $n$, define the set:
  \begin{equation}
    \label{eq:en}
    E(n) = \{R_i(j) : 0\leq i,j\leq n\},
  \end{equation}
  and let $h$ denote an increasing time-constructible function such that:
  \begin{equation}
    \label{eq:hn}
    h(n) > \max E(n),
  \end{equation}
  for instance, $h$ may explicitly compute $\max E(n)$ and spend that many steps idling by decreasing a counter.
  
  Let us show that for every $n$, there exists an element in $\mathrm{Im}(R_n)\setminus\mathrm{Im}(h)$.
  The set $\{h(0), \dots, h(n-1)\}$ cannot contain $\{R_n(0), \dots, R_n(n)\}$ because $R_n$ is injective
  (since it is increasing).
  So there is an element $i$ of $\{0, \dots, n\}$ such that $R_n(i)$ does not belong to $\{h(0), \dots, h(n-1)\}$.
  We have $R_n(i) < h(n)$ by Equations~\eqref{eq:en}--\eqref{eq:hn};
  since $h$ is increasing, $R_n(i)$ is not in $\mathrm{Im}(h)$.
  The existence of desired formula $\psi$ follows from Lemma~\ref{lem:specim}.
\end{proof}

\begin{proof}[Proof of Theorem~\ref{thm:bad}.]
  Let $\psi$ and $d$ be given by Lemma~\ref{lem:diag} and assume that $f$ is a polynomial reduction from either SAT or UNSAT to \textsc{$\psi$-Dynamics}.
  Both the spectrum of $\psi$ and its complement are infinite, so $\psi$ is nontrivial.
  If there exists some polynomial $P$ such that $f$ has a robust meagerness set,
  then by Lemma~\ref{lem:meagersat} there exists a polynomial-time algorithm solving SAT on a robust set of instance sizes.
  Otherwise, since $\mathrm{Spec}(\psi)\subseteq\mathbb{N}^{(d)}$, Lemma~\ref{lem:meagerenum} implies that there is an increasing primitive-recursive map $\mu$ such that,
  for every $n$, the quantity $\mu(n)^d$ is the size of a model of $\psi$.
  But then, by Lemma~\ref{lem:diag}, one of those sizes will not be contained in the spectrum of $\psi$: a contradiction.
\end{proof}


\section*{Discussion and Future work}

One could consider different parametrizations of \textsc{$\phi$-Dynamics}.
Let us first point out that parametrization by the size or quantification rank of the formula fails.
The formula $\exists x: F(x,x)$ expresses the property: ``$F$ has at least one fixed point.''
That question is {\ensuremath{\mathsf{NP}}}-hard: given an instance $S$ of SAT, produce an AN with $|S|$ Boolean automata that evaluates its own configuration on $S$;
if it finds ``true'', nothing changes; if it finds ``false'', it transitions to the next configuration (in lexicographic order).
The formula above is virtually the smallest possible by any reasonable parameterization of logic formulae,
so there is no hope to get fixed-parameter tractability if the parameter concerns the formula.
Moreover, in this reduction every transition graph produced is either a huge cycle or a sequence of paths ending in loops.
This implies that they all have treewidth~$1$, so parameterization by the treewidths of transition graphs also fails:
we have {\ensuremath{\mathsf{NP}}}-difficulty even when the treewidth is guaranteed to be at most~$1$.

Another relevant parameter, when taking the automata networks point of view, is the size of the alphabets $Q_v$ used at each nodes.
For instance, as it is usually the case in the automata networks literature, one could consider \textsc{$\phi$-dynamics} restricted to automata networks where all nodes share the same alphabet of size $q$.
Our reduction in Lemma~\ref{lem:sat} fails in this settings as it produces automata networks with possibly two different alphabet sizes among their nodes.
We do not know whether our main theorem holds for a fixed alphabet, but it is interesting to note that some formulae become trivial when fixing the alphabet: for instance, a formula asking that each configuration belong to a cycle of length two has no model with a ternary alphabet.

On the other hand, it remains to fully characterize which nonarborescent MSO sentences yield an {\ensuremath{\mathsf{NP}}}- or {\ensuremath{\mathsf{coNP}}}-hard problem,
and what happens with those that do not.
In particular, Theorem~\ref{thm:bad} does not say whether the formula $\phi$ has a polynomial-time solvable \textsc{$\phi$-Dynamics} problem.
We do not know whether it could be the case for some $\phi$ under reasonable complexity assumptions. 

It would be interesting to have average-case difficulty rather than worst-case difficulty,
e.g., to show that ``draw a configuration at random and check whether it is a fixed point'' is not a good algorithm to find fixed points in general.
In the same vein, general hardness results on \emph{probabilistic} automata network would also be welcome.

Finally, let us recall that the main result of this paper do not hold when restricting to some natural families of automata networks and using other input representation than circuits: for instance 
 threshold automata networks or automata networks of bounded degree can be naturally described as labeled graphs. In such cases, arborescent formulae can have a polynomial-time \textsc{$\phi$-Dynamics} problem, like ``being a constant function''. It would be interesting to understand what properties become tractable in these natural restrictions (which are often considered in the literature) and which fragment of MSO remains intractable.

\section*{Acknowledgments}

The authors are very grateful to Édouard Bonnet (LIP, France) for the proof of Proposition~\ref{pro:saturating}.

\printbibliography

\end{document}

