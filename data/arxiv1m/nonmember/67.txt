\section{Introduction}
\label{intro}
Motivated by a real-world problem faced by the company Sportradar, which provides betting odds on sports matches, we study a complex personnel scheduling problem. Workers are assigned tasks for supervision. 
Each worker has a specific set of skills that allows them to cover different tasks with varying levels of difficulty. Workers may work on multiple tasks in parallel, with their personal skill determining the limit for parallel tasks. Furthermore, each worker provides their availabilities, within which their shifts can be scheduled. Each worker has requirements for break as well as rest times, depending on the legal requirements at the worker's location. Breaks may be split into parts, however each break incurs a preparation time that is required before resuming work following the break. 
The number of tasks exceeds the 
capacity for coverage. Each task has a given 
priority score  
and asks for a specific skill level in the corresponding task group. The objective is to maximize the total priority score of all assigned tasks, while minimizing the penalty incurred for assigning operators with a skill level lower than the one desired for the assigned tasks. 
We propose a mixed integer linear programming (MIP) formulation for the considered problem and we develop an adaptive large neighborhood search (ALNS) algorithm to solve large-scale instances in a short amount of time. We compare the solutions obtained by the heuristic approach with optimal solutions obtained from solving the developed MIP model 
with CPLEX. Furthermore, the proposed ALNS 
is applied to large-scale real-world data provided by Sportradar. We note that the ideas proposed in this paper  
are not limited to the application to the considered problem, but may 
be used in solution approaches to other  personnel scheduling, rostering and timetabling problems. Their main focus is the requirement of task selection and assignment based on priority scores. Similar problems can be found in aviation and railway traffic like flight cancellations due to general staff shortages or strikes, as well as medical triage. 

The remainder of the paper is structured  
as follows. In Section \ref{rel}, we provide an overview of related work and we present, in Section \ref{def}, 
the  developed mathematical model.  
Section \ref{method} is devoted to the description of the proposed adaptive large neighborhood search algorithm. 
In Sections \ref{results} and \ref{study}, computational results are presented,   
including information on the
proposed test instances, comparison to optimal and to company solutions  
as well as managerial insights derived from changes in the weights of the objective function. Section \ref{conc} concludes the paper and provides possible directions for future research.

\section{Related Work}
\label{rel}
To the best of our knowledge, the problem proposed in this paper has not been considered in the literature before. However, it shares characteristics with a number of well-studied problems. Therefore,
we review the literature in each of these different areas and  point to the main differences and similarities between the reviewed work and the problem considered in this paper.

First and foremost, the problem proposed in this paper belongs to the field of personnel scheduling and rostering problems. With the main goal of the problem being the construction of a schedule for available operators by assigning tasks that already have starting and ending times, the problem is related to 
staff scheduling problems arising in the airline industry, in (public) transportation, or hospitals. 
A main difference between the problem addressed in this paper and those staff scheduling problems 

is the possibility to carry out multiple tasks in parallel. 
\cite{chu2007generating}, e.g., propose a goal programming approach for scheduling and rostering airport personnel and  \cite{maenhout2010hybrid} develop a hybrid scatter search approach for the 
airline crew rostering problem. 

\cite{yunes2005hybrid} consider the crew scheduling and rostering problem in an urban bus transit problem and solve it by means of hybrid column generation approaches. A nurse rostering problem, considering shift assignments and rest times, is, e.g., solved by \citet{solos2013generic} using variable neighborhood search. 
Differing from the problem addressed in this paper, a majority of the research on personnel rostering specifically requires to cover all tasks, with objectives often targeting minimization of (assignment) costs. However, also alternative objectives are addressed, such as, e.g., equity in terms of workload targets \citep{prot2015two}. 

From a methodological point of view, \cite{barrena2013fast} as well as \cite{dong2020integrated} successfully implement ALNS for train scheduling and timetabling problems, while \cite{mansini2019optimizing} use ALNS to schedule physicians in a hospital ward and \cite{sorensen2012international} apply ALNS to high school timetabling.

A subfield of personnel scheduling that is 
relevant for the problem addressed in this paper, is the field of multi-skilling problems, 
where each worker has a set of predefined skills that enable them to carry out a certain subset of the available 
tasks. \cite{cuevas2016mixed}, e.g., propose a mixed integer program for the short-term multi-skilled workforce tour scheduling problem, 
where workers' shifts and days off are planned while assigning activities to shifts.
\cite{de2018three} propose a three stage MIP approach for optimizing skill mix and training schedules for aircraft maintenance personnel. Furthermore, \cite{KPDH10} use ALNS to solve the problem of service technician routing and scheduling to minimize coverage cost, while also taking skill levels of technicians into account.

 
The problem considered in this paper 
also features the aspect of task selection: 
tasks need to be chosen from a large pool of available tasks with the goal of maximizing the total benefit of covered tasks. While \cite{vijaykumar1998task} already considered the problem of task selection for a multiscalar processor in the last millennium, the field only recently received more attention. \cite{song2010novel}, e.g., consider task selection and allocation for collaborative cloud service platforms and solve the problem using an adaptive filter in combination with a heuristic algorithm. Related problems are often considered in the context of crowd-sourcing. \cite{abououf2019multi} consider multi-worker multi-task selection in mobile crowd sourcing using a genetic as well as a tabu search algorithm, while \cite{deng2016task} consider task selection for spatial crowd-sourcing with the help of dynamic programming and branch-and-bound. \cite{li2018task} propose a game theoretical approach to solve the problem of task selection and scheduling for food delivery and \cite{shaghaghi2017task} consider task selection and scheduling for multifunction radar systems and solve the problem to optimality using branch-and-bound.

Due to the requirement of 
task selection and assignment to build shifts that contain the highest-value tasks, the problem can also be seen 
as a generalization of the bin packing problem.  
Reformulations of scheduling problems as bin packing problems have been proposed going back as far as the 1970s \citep{garey1976resource,coffman1978application}. 
\cite{leinberger1999multi} consider multi-capacity bin packing with application to job scheduling problems and \cite{vijayakumar2013dual} formulate a dual bin packing approach in order to schedule surgical cases in a hospital. More recently, 
\cite{li2018single} have considered a single bin packing machine scheduling problem with two-dimensional bin packing constraints and \cite{witteman2021bin} address  
aircraft maintenance task allocation from a bin packing perspective. Using a hybrid genetic based approach, \cite{su2021hybrid} consider the problem of unrelated parallel workgroup scheduling from a bin packing perspective. Related to the approach considered in this paper, ALNS has been successful at solving bin packing problems. \cite{he2021adaptive} use ALNS to solve the circle bin packing problem and \cite{zeng2021adaptive} propose an ALNS approach for single machine batch processing with two-dimensional bin packing constraints while \cite{zeng2021adaptive2} apply ALNS to a two-dimensional packing problem with conflict penalties.

The problem considered in this paper is also related to resource-constrained project scheduling problems (RCPSPs) in that the assignment of tasks to workers must take capacity restrictions on each worker into account. In contrast to general RCPSPs however, tasks are independent of one another and have fixed starting and ending times. The goal is therefore to use the available resources (worker capacity) as efficiently as possible by choosing the most valuable tasks. Recent research on RCPSPs has, e.g., addressed 
resource leveling 
to keep the use of a scarce resource as balanced as possible \citep{li2018effective} and flexible resource profiles in which resource usage may vary at different times \citep{naber2014mip}. 
Alternative activity chains are, e.g., considered by \cite{tao2017scheduling} and \cite{hauder2020resource}. 
\cite{lova2000multicriteria} address 
RCPSPs with objectives differing from the usual minimization of the makespan as well as multiple projects running in parallel. 
Heuristic approaches related to the approach developed in our paper have been used for RCPSPs to great success, for example by \cite{palpant2004lssper} as well as by \cite{muller2009adaptive,muller2011adaptive}.

Based on the personnel scheduling  
literature review of 
\cite{van2013personnel}, the problem we address falls into the class 
of personnel task scheduling problems, which is defined as follows \citep{krishnamoorthy2001personnel}: a set of tasks with fixed start and end times have to be assigned to a workforce with different qualifications allowing them to carry out only a subset of the available tasks within predefined shifts. In the shift minimization task scheduling problem (SMTSP), the objective is to minimize the total number of employees. The SMTSP relates to list coloring on interval graphs \citep{smet2014shift}, which is NP-complete \citep{bonomo2009exploring}.
We introduce several new aspects 
not considered in the original definition, most important of which is the required task selection.  We therefore refer to the proposed problem as personnel task scheduling problem with task selection (PTSP-TS).
The PTSP-TS generalizes the interval scheduling problem with given machines, where a set of tasks with given start and end times is to be scheduled on a given set of machines and the objective is to maximize the (weighted) number of assigned tasks \citep{kolen2007interval}. The variant where tasks may only be carried out by a subset of the machines (which relates to the skill requirements considered in this paper), is known to be NP-hard \citep{kolen2007interval,arkin1987scheduling}.



\section{Problem Definition}
\label{def}

\allowdisplaybreaks
In the PTSP-TS, tasks are to be assigned to operators to maximize the benefit of covered tasks, while minimizing the penalty incurred from assigning lower-skilled operators. In Figure \ref{figure:1}, we show the solution obtained for a toy example using three operators and a total of 996 assignable tasks. Each operator has given skills to cover different tasks. In our application, these skills concern the supervision of different types of sports games.  
In the considered planning horizon of 34 hours, shifts are to be constructed within five availabilities. In the figure, each of these availabilities is represented by a rectangle coloured in teal. The planned shift within the availability is depicted by a blue frame. 
In addition, we give its starting and ending times. Within each shift, each assigned task is represented by a purple rectangle. Its length represents the actual length of the task. The provided floating point value represents the amount of an operator's attention a task requires, later referred to as required bandwidth. The gray bars within a shift give the operator's bandwidth usage. Their heights vary depending on the total bandwidth currently required. Gray bars reaching the top of the shift frame indicate that the bandwidth is fully used. This is, e.g., the case for Operator A with only two tasks in the beginning of the second shift, while six parallel tasks can be feasibly assigned towards the end of the shift.      Below each operator, we display the total assignment score of all the tasks assigned to an operator and the total penalty from assignments below the operator's provided skill level. In this toy example, no tasks below the operators' skill levels are assigned. Therefore, this value is zero. 

\begin{figure}
\caption{Graphical display of the assignment of tasks to operators for a toy example} \label{figure:1}
\includegraphics[width=\textwidth, frame]{toy.PNG}
\centering
\end{figure}

In order to more formally state the problem, 
we define a set of tasks $V$ and a set of operators $O$. Each task $i$ has a given priority $p_i$, as well as known requirements for working capacity $b_{is}$ (referred to as bandwidth) depending on 
the shift $s$ it is assigned to. We note that we do not explicitly model operators but shifts of operators where the bandwidth requirement depends on the operator $o$ the shift $s$ belongs to. The set $S_o$ contains the shifts of operator $o$. Each task requires a specific skill level. Assignments to shifts of lower skilled operators incur a penalty of $d_{is}$. Operators which do not dispose of a certain skill at all cannot be assigned tasks requiring the respective skill. Each task belongs to one task group $\sigma$ out of the set of task groups $P$. The set of all tasks $V$ is composed of a set of mandatory tasks $U$ that have to be assigned and a set of optional tasks $W$  ($V = U \cup W$). 

We consider time to be discrete with an available number of time buckets $|T|$. 
Each operator defines a set of availability periods (referred to as availabilities). Within each availability at most one shift can be planned.
As such, each shift is limited by its corresponding availability given by earliest starting time $e_s$ and latest ending time $l_s$;  $T_s$ provides the set of time buckets in which shift $s$ can be planned. Likewise, each task $i$ has a set of time buckets $R_i$ it occupies. Then, the set $V_{st}$ gives the set of tasks that can be assigned to shift $s$ in time bucket $t$. 
In addition, a minimum shift length $\alpha_s$ and a maximum shift length $\omega_s$ is specified.  Every shift has requirements specific to each operator $o$ for break length $\gamma_o$ as soon as the maximum duration of a shift without break $\chi_s$ is exceeded, as well as rest length $\delta_o$ in between shifts of operator $o$. This implies that there may be availabilities in which no shifts are planned. The total break length may be consumed over multiple smaller breaks. However, each partial break has to have a minimum length $\beta_o$, depending on the operator $o$, and each separate break requires a preparation time $\rho$, during which an operator cannot perform any tasks. This preparation time does not count towards the length of the break. Each shift has further limitations on breaks by only allowing breaks after $\nu_s$ hours and only up until $\lambda_s$ hours into the shift. 
 The complete list of notation used for parameters and variables is given in Table \ref{tbl:params}. Using this notation, 
 we formulate the PTSP-TS as the following binary linear program:

\begin{table}[t!b]
\caption{Notation \label{tbl:params}}
\centering
\small
\begin{tabular}{lll}
\toprule
Sets and parameters && \\
\midrule
    $T$ & set of time buckets \\
    $U$ & set of mandatory tasks \\
    $W$ & set of optional tasks \\
	$V = U \cup W$ & set of all tasks \\
	$O$ & set of operators \\
	$S$ & set of shifts \\
    $S_o$ & set of shifts of operator $o$ \\
    $S_i$ & set of shifts that can cover task $i$ \\
    $T_s$ & set of time buckets of availability period in which shift
    $s$ can be planned\\
    $R_i$ & set of time buckets of task $i$ \\
    $V_{st}$ & set of tasks that can be assigned to shift $s$ in time bucket $t$ \\
	$P$ & set of task groups \\
	 \\
	$[e_s,l_s]$ & earliest starting time and latest ending time of shift $s$ (availability)\\
	$b_{is}$ & required bandwidth of task $i$ in shift $s$ \\
	$p_i$ & priority score of task $i$ \\
	$d_{is}$ & skill deviation of task $i$ if assigned to shift $s$ \\
	$\alpha_s$ & minimum duration of shift $s$ \\
	$\omega_s$ & maximum duration of shift $s$ \\
	$\chi_s$ & maximum duration of shift $s$ without requiring a break \\
	$\rho$ & preparation time \\
	$\beta_o$ & minimum partial break duration of operator $o$ \\
	$\gamma_o$ & minimum total break duration of operator $o$ \\
	$\delta_o$ & minimum rest duration of operator $o$\\
	$[\nu_s,\lambda_s]$ & time window of break for shift $s$\\
	$w_1$,$w_2$ & weights of objectives in the objective function \\
        $k$ & upper limit on the number of different groups for parallel tasks \\
\toprule
Decision variables && \\
\midrule
    \multicolumn{2}{l}{$x_{is}$=
	$\begin{cases}
		1, & \text{if task $i$ is  assigned to shift $s$}\  \\
		0, & \text{otherwise}
	\end{cases}$}\\
	\multicolumn{2}{l}{$u_{st}$=
	$\begin{cases}
		1, & \text{if shift $s$ is activated in time bucket $t$}\  \\
		0, & \text{otherwise}
	\end{cases}$} \\
	\multicolumn{2}{l}{$r_{st}$=
	$\begin{cases}
		1, & \text{if  shift $s$ deactivated in time bucket $t$}\  \\
		0, & \text{otherwise}
	\end{cases}$} \\
	\multicolumn{2}{l}{$v_{st}$=
	$\begin{cases}
		1, & \text{if time bucket $t$ in shift $s$ counts as break}\  \\
		0, & \text{otherwise}
	\end{cases}$} \\
	\multicolumn{2}{l}{$a_{ts\sigma}$=
	$\begin{cases}
		1, & \text{if task of group $\sigma$ is assigned in time bucket $t$ in shift $s$}\  \\
		0, & \text{otherwise}
	\end{cases}$} \\
	\multicolumn{2}{l}{$z_s$=
	$\begin{cases}
		1, & \text{if shift $s$ is enabled}\  \\
		0, & \text{otherwise}
	\end{cases}$} \\
	\multicolumn{2}{l}{$\hat{z}_s$=
	$\begin{cases}
		1, & \text{if shift $s$ requires a break}  \\
		0, & \text{otherwise}
	\end{cases}$} \\
\bottomrule
\end{tabular}
\end{table}

\allowdisplaybreaks

\begin{align}
    \max \hspace{2mm} w_1 \sum_{i\in V} \sum_{s \in S_i} p_i x_{is} - w_2 \sum_{i \in V} \sum_{s \in S_i} d_{is} x_{is} \label{objf}
\end{align}
subject to:
\begin{align}
	\sum_{s \in S_i} x_{is} & = 1 && \forall i \in U \label{eq1}\\
	\sum_{s\in S_i} x_{is} & \leq 1 && \forall i \in W \label{eq2}\\
	x_{is} & \leq z_s	&& \forall i \in V, s \in S_i \label{eq3}\\
	\sum_{i \in V_{st}} x_{is} b_{is} & \leq u_{st} && \forall s \in S, t \in T_s \label{eq4}\\
	u_{st+1} & \geq u_{st} && \forall s \in S, t \in T_s, t \leq |T_s|-1 \label{eq5}\\
	\sum_{t=e_s}^{l_s} u_{st}& \leq z_sM  && \forall s \in S \label{eq6}\\
	r_{st+1}& \geq r_{st} &&  \forall s \in S, t \in T_s, t \leq |T_s|-1\label{eq7}\\
	\sum_{i \in V_{st}} x_{is} b_{is} & \leq 1-r_{st} &&  \forall s \in S, t \in T_s \label{eq8}\\
	\sum_{t=e_s}^{l_s} r_{st} & \leq z_sM && \forall s \in S \label{eq9}\\
	\sum_{t=e_s}^{l_s} (u_{st} - r_{st}) & \geq \alpha_s z_s &&  \forall s \in S\label{eq10}\\
	\sum_{t=e_s}^{l_s} (u_{st} - r_{st}) & \leq \chi_s z_s + (\omega_s - \chi_s) \hat{z}_s &&  \forall s \in S\label{eq10b}\\
    \sum_{t'=t+1}^{t+\rho} \sum_{i \in V_{st'}} x_{is}b_{is} & \leq \rho - \rho v_{st} && \forall s \in S, t \in T_s, t \leq l_s-\rho \label{eq11}\\
    \sum_{i \in V_{st}} x_{is} b_{is} & \leq 1 - v_{st} &&  \forall s \in S, t \in T_s \label{eq12}\\
	\sum_{t=e_s}^{l_s} v_{st} & \geq \gamma_o\hat{z}_s && \forall o \in O, s \in S_o \label{eq13} \\
	v_{st} & \leq u_{st} - r_{st} && \forall s \in S, t \in T_s \label{eq14} \\
	v_{st} & \leq u_{s,t-\nu_s} && \forall s \in S, t \in T_s, t \geq \nu_s \label{eq15}\\
	v_{st} & \leq 1-u_{s,t-\lambda_s+1} && \forall s \in S, t \in T_s, t \geq \lambda_s \label{eq16}\\
	\sum_{t' = t+1}^{t + \beta_o -1} v_{st'} &\leq \beta_o (v_{st} + v_{s,t+\beta_o}) && \forall o \in O, s \in S_o, t \in T_s, t \leq |T_s|-\beta_o  \label{eq17}\\
	a_{ts\sigma} & \geq x_{is}  && \forall s \in S, i \in V, t \in R_i, \sigma \in P, \label{eq18}\\
	\sum_{\sigma \in P} a_{ts\sigma} & \leq k && \forall s \in S, t \in T_s \label{eq19}\\
	\sum_{t'=t+1}^{t+\delta_o} u_{s't'} & \leq (1-u_{st}+r_{st})\delta_o &&  \forall o \in O,  s \in S_o, s' \in {S_o|s' \neq s}, t \in T_s \label{eq20}\\
	x_{is} & \in \{0,1\}  &&\forall i \in V, S \in S_i \label{eq23}\\
	u_{st} & \in \{0,1\}  &&\forall s \in S, t \in T_s\\
	r_{st} & \in \{0,1\}  &&\forall s \in S, t \in T_s\\
	v_{st} &\in \{0,1\}  &&\forall s \in S, t \in T_s\\
	a_{ts\sigma} &\in \{0,1\}  && \forall s \in S, t \in T_s, \sigma \in P \\
	z_s & \in \{0,1\} &&\forall s \in S \\
	\hat{z}_s & \in \{0,1\} &&\forall s \in S \label{eq29}
\end{align}

The objective function \eqref{objf} consists of two parts: the sum of all assigned tasks 
weighted by their corresponding priority $p_i$ and the sum of all penalties that occur due to the assignment of tasks to operators with a lower than optimal skill level for the corresponding task group $d_{is}$. The overall function maximizes the difference between the total priority and the total penalty, each of which are individually weighted using $\mathnormal{w_1}$ and $\mathnormal{w_2}$. 

The first groups of constraints \eqref{eq1}, \eqref{eq2}, and \eqref{eq3} ensure the limits for the assignments of tasks. Tasks are split into mandatory tasks $U$ and optional tasks $W$. All mandatory tasks have to be assigned to exactly one single shift, while for all other tasks assignment is optional. Furthermore, constraints \eqref{eq3} require that a task may only be assigned to a shift if that shift has been enabled using the binary variable $z_s$.

Constraints \eqref{eq4}, \eqref{eq5}, and \eqref{eq6} set the limits for the binary variable $u_{st}$ depicting whether a given shift $s$ is active during the time bucket $t$. In constraints \eqref{eq4} the limit for the bandwidth usage is given. Each task requires a certain amount of an operator's attention referred to as bandwidth $b_{is}$. This bandwidth depends on the operator's skill as well as the task's complexity. The bandwidth used at any given time may only exceed zero if the shift is indeed active. Furthermore, as time is considered discrete, once a shift has been activated, the binary variables associated with the following time buckets will be $1$ until the final time bucket. Finally, constraints \eqref{eq6} ensure that the whole shift needs to be enabled using $z_s$ in order to be activated. If there is a surplus in operator capacity, an operator's shift can stay disabled, meaning he or she will not be working that shift.

Similar to the last four constraints, the shift deactivator $r_{st}$ has to be constrained. Constraints \eqref{eq7} ensure that once a shift $s$ has been deactivated, it will stay deactivated. In constraints \eqref{eq8} the limit for used bandwidth is set to zero once the shift $s$ has been deactivated. Constraints \eqref{eq9} state that a shift $s$ may only be deactivated if it is actually enabled.
Constraints \eqref{eq10} and \eqref{eq10b} ensure that the required minimum and maximum lengths per shift $(\alpha_s$ and $\omega_s)$ are respected and break requirements are met.

The following seven constraints ensure that each shift $s$ includes the required break times. Constraints \eqref{eq11} ensure that a preparation time for booting up to work after any break is considered. For an operator $o$ a time bucket $t$ can only be counted towards the required break time $\gamma_o$ if there are no assignments made after it for the length of the preparation time $\rho$. Constraints \eqref{eq12} ensure that the time bucket $t$ may only be counted as a break as long as the bandwidth is zero. Constraints \eqref{eq13} require that the sum of the break times has to be at least the minimum length if the shift length exceeds a certain limit. The next three sets of constraints $($\eqref{eq14} through \eqref{eq16}$)$ set the limits for whenever a time bucket may actually be counted as break. Constraints \eqref{eq14} require that only if a shift $s$ has been turned on, but not yet off, a break may be counted. Constraints \eqref{eq15} and \eqref{eq16} require all breaks to consider the earliest break starting time $\nu_s$ and the latest break end $\lambda_s$. Finally, constraints \eqref{eq17} require that for each operator $o$ any minimum break length requirements $\beta_o$ are respected.

Furthermore, the number of allowed task groups $P$ covered in a shift $s$ in a time bucket $t$ is restricted to $k$. Constraints \eqref{eq18} require that for each task group $\sigma$ the task group limit $a_{ts\sigma}$ is set to one if at least one task of that group is assigned at the time. Constraints \eqref{eq19} ensure that the total number of task group counting variables set to one at any time does not exceed the limit of $k$.

Between shifts covered by the same operator $o$, a rest time $\delta_o$ has to be maintained for legal reasons. Constraints \eqref{eq20} ensure that this rest time is respected in-between all shifts $S_o$ for each operator $o$. 

The domains of the variables are defined in \eqref{eq23}-\eqref{eq29}.\\



\section{Adaptive Large Neighborhood Search}
\label{method}
In order to solve the PTSP-TS, an adaptive large neighborhood search type algorithm is designed. Large neighborhood search (LNS) is a metaheuristic search concept proposed by \cite{shaw1998} and it is related to the ``ruin and recreate'' principle by \cite{schrimpf2000record}. It was then further developed for routing and scheduling problems by \cite{RP06a} with the introduction of an adaptive layer which changes the selection probability of  repair and destroy operators based on their past performance. 
Since then it has become one of the most popular heuristic search schemes in the routing and scheduling field \citep{pisinger2010large}. 

ALNS works as follows (see Algorithm \ref{alg:lns-allg}). In a first step, a feasible solution $s$ is generated. In every iteration, a removal operator $d$ and a repair operator $r$ are chosen based on their weights that change due to performance. In a next step, tasks are removed from $s$ using the chosen removal operator $d$ and put into the pool of not assigned tasks. Then, using the chosen repair operator $r$, tasks are (re-)inserted into the shift plan. In the case where the resulting solution $s$ meets the acceptance criteria, it replaces $s$. In the case where it is better than the best solution found so far, it replaces $s_{best}$. This is repeated until some stopping criterion is met.

\begin{algorithm}[H]
	\caption{ALNS \label{alg:lns-allg}}
	\begin{algorithmic}[1]
		\STATE generate a starting solution $s$;
		\STATE set $s_{best} := s$
		\REPEAT 
		\STATE choose a removal operator $d$ and a repair $r$ operator 
		\STATE  apply $d$  to  $s$ yielding $s'$
		\STATE  apply  $r$ to $s'$ yielding $s''$
		\STATE  decide if $s''$ is accepted as new incumbent solution; if yes $s \leftarrow s''$ 
		\STATE  check if $s''$ is better than $s_{best}$; if yes, $s_{best} \leftarrow s''$
		\STATE update the scores and weights of the operators
		\UNTIL a given stopping criterion is met
		\STATE return $s_{best}$
	\end{algorithmic}
\end{algorithm}

In the following we describe the different ingredients in further detail: the deployed destroy and repair heuristics, the developed randomization approach, the acceptance scheme as well as the adaptive mechanism.

\subsection{Destroy Heuristics}
We employ four different removal heuristics. .
Three of these heuristics - random, worst, and operator removal - are based on existing work \citep[e.g.,][]{KPDH10,RP06a} and tailored to the characteristics of 
the PTSP-TS.
The fourth operator, named time-based removal, exploits the fact that in our problem, tasks have fixed starting and ending times.  

\subsubsection{Random Removal}
\label{sec:randRem}
Random removal randomly chooses assigned tasks, removes them from the solution and adds them to the pool of unassigned tasks. 
It is implemented as follows. In a first step, a random number $l$ is drawn from the range \tt{chancelimits}. Then, for every currently assigned task, a random number $r$ is drawn and if  $r \leq l$, the respective task is removed from the schedule. 




\subsubsection{Worst Removal}
Worst removal completely removes the shifts that contribute the lowest to the objective. It is specifically designed to select shifts that contribute unnecessarily high penalties, as well as shifts that are low on assignment density. The number of shifts destroyed is chosen randomly as follows: a random number $l$ is drawn from \tt{chancelimits} and let $N$ denote the number of currently planned shifts, then the worst $N l$ shifts are removed from the solution. 

\subsubsection{Operator Removal}
The operator removal algorithm removes all shifts of a given operator. It follows a similar logic as the random removal heuristic. Instead of removing individual tasks from the solution, a random number $r$ is drawn for each operator and in the case where $r \leq l$ (see Section \ref{sec:randRem}), all shifts of the respective operator are removed from the solution.

\subsubsection{Time-based Removal}
The time-based removal heuristic makes a vertical slice through the entire solution. The idea is to enable the switch of tasks between different shifts that would fit similar time slots. This removal method randomly selects a start time $t \in T$ as well as a length $l$ in the range \tt{widthlimits}, removing all assigned tasks $i$ for which $R_i \cap \{t, ..., t+l\} \neq \emptyset$, i.e., even if the task falls only partially into the time interval, it is removed. 

\subsection{Repair Heuristics}
All repair heuristics rely on sorting all possible task to operator assignments according to different criteria and then performing all feasible task to operator assignments in this order. The first three heuristics (A,B,C) rely on penalty and priority based sorting, the next heuristic (D) takes into account the objective function, and finally, the last heuristic (E) considers the value of assigning a task to an operator based on the time and bandwidth it will occupy. The heuristics are described in further detail in the following.

\subsubsection{Penalty and Priority Sorting}

The first three repair heuristics rely on sorting all task to operator assignments according to task $Priority$ $p_i$ and assignment $Penalty$ $d_{is}$. We ensure deterministic sorting of assignments by using a number of sequential sorting criteria. We use $Penalty$ as the main sorting factor in order to maximize the number of assignments to operators that have the desired skill level. $Priority$ is used as the second sorting value, with assignments with higher priority being preferred. The first repair heuristics both start sorting according to $Penalty$ ahead of $Priority$ and introduce the following additional tie breakers:

\begin{itemize}
	\item $A$: \{$Penalty,Priority,skillFitting$\}
	\item $B$: \{$Penalty,Priority,skillFitting*(-1)$\}
	\item $C$: \{$Penalty,Priority,Bandwidth*(-1),skillFitting$\}
\end{itemize}

As the first additional tie breaker we use a value called $skillFitting$. The calculation of this value differs depending on whether the operator fulfills the desired skill level of the considered task. If they do, we calculate the value of $skillFitting$ to be equal to $DesiredSkill - ActualSkill$. This gives preference to assigning tasks to operators that fulfill the skill requirement as closely as possible, in order to make sure  that the capacities of our highest-skilled operators are kept for the most difficult tasks. If the operator's skill level is lower than the desired level, then this value is equal to the $Penalty$ $d_{is}$. For our repair operators $A$ and $B$ we take $skillFitting$ as the third tie breaker, however for operator $B$ the value is inverted. This usage of the tie breaker has different objectives: While regular usage of the $skillFitting$ value tries to retain as much capacity of higher-skilled operators as possible, using the inverted value tries to fill up the shifts of the higher-skilled operators by using the tasks with the highest $Priority$. For sorting operator $C$ we introduce another differentiation value $Bandwidth$. $Bandwidth$ is the capacity a task occupies when assigned to a specific shift (denoted as $b_{is}$ above). As our problem allows for the assignment of multiple tasks in parallel, this value ranges from 1 (full capacity) down to $\frac{1}{6}$. The value of $Bandwidth$ for a specific assignment is dependent on the task as well as the operator's skill for parallel coverage. We use the inverted value as assignments using a smaller amount of capacity are generally preferred.


\subsubsection{Objective Sorting}
Sorting operator $D$ now combines the usage of $Penalty$ and $Priority$ into the value $Objective=w_1*p_i - w_2*d_{is}$ which is the actual value an assignment contributes to the objective function.

\begin{itemize}
\item $D$: \{$Objective,Bandwidth,skillFitting$\}
\end{itemize}

Similar to sorting operator $C$ we use $Bandwidth$ and $skillFitting$ as subsequent tie breakers.

\subsubsection{Efficiency Sorting}\label{eff}
\allowdisplaybreaks
For our fifth and final sorting operator $E$ we introduce a new value called $Efficiency$. This value is calculated using the following formula: $Efficiency = Objective$ $/(Bandwidth*Length)$. $Efficiency$ therefore gives us the contribution per occupied capacity of an operator. The $Efficiency$ of an assignment of tasks with the same priority grows the lower the occupied $Bandwidth$ of an operator and the shorter the task in general.

\begin{itemize}
	\item $E$: \{$Efficiency,Priority,Bandwidth*(-1),Groups*(-1)$\}
\end{itemize}

As first and second tie breaker we use the previously introduced values for $Priority$ and $Bandwidth$. However, due to the structure of the $Efficiency$ value, we require a tie breaker that is different from $skillFitting$. Here, we give preference to operators that have the least flexibility of covering different task groups. The value $Groups$ chosen as tie breaker is defined as the number of different task groups that an operator is skilled in. The skill levels are not considered here. As we aim at prioritizing assigning staff with low flexibility, the value of $Groups$ is inverted.

\subsection{Starting Solution}
To obtain a starting solution, we employ the repair operator Efficiency Sorting (described in \ref{eff}) to sort all tasks of the instance. We then construct an assignment by "repairing" the initially empty assignment, inserting tasks in the order provided by the sorting mechanism. Only feasible task assignments are considered.

\subsection{Acceptance Criteria}
For our implementation of ALNS, we consider three possibilities of handling a newly created solution. New solutions achieving a globally best objective value are immediately accepted and stored for further use. If a new solution has an objective value that is at maximum .5\% lower than the current incumbent solution, then the solution is accepted as new incumbent solution for the next iteration. All solutions more than .5\% worse than the current solution are discarded. In this case, the next iteration starts using the assignments of the incumbent solution. 

\subsection{Choice of Destroy and Repair Heuristics}
In accordance with \cite{RP06a}, we use separate weights $\eta_{h}$ for every possible repair and destroy heuristic $h$. Ahead of each iteration of the ALNS, destroy and repair heuristics are randomly chosen based on their weights. The result of each iteration (overall improvement, temporary improvement and rejection) is stored for the chosen heuristics. After a given amount of iterations $SegLen$, referred to as segment, the weights of all heuristics are updated based on their performance in the past segment. For the following segment, these updated values are used for randomized selection. The weights are updated periodically during the search, with the length of each segment staying the same.
The probability $\phi_{h}$ for a repair heuristic to be chosen for an iteration is calculated as follows:

\begin{align}
	\phi_{h} = \frac{\eta_{h}}{\sum_{{h}'=1}^{n_{h}}\eta_{{h}'}} 
\end{align}
The choice of destroy heuristic is made in the same way.

For updating the weights of the heuristics after each segment we use an approach that is based on \cite{RP06a}. Every repair and destroy heuristic receives an initial score $\sigma$ that increases in each iteration a heuristic was used, based on its performance. Scores are updated as follows:

\begin{align}
	\sigma = &
 \begin{cases} 
	\sigma + \epsilon_1, &\text{if $s''$ improves the global best solution } s_{best}, \\
	\sigma + \epsilon_2, &\text{if $s''$ improves the incumbent solution } s, \\
	\sigma + \epsilon_3, &\text{if $s''$ is accepted as new incumbent $s$ although it is worse},\\
	\sigma, &\text{otherwise. } \notag
\end{cases}
\end{align}

In our computational study, we evaluate this approach, using different parameter settings and we also consider keeping $\epsilon_3 = 0$, which results in no reward for solutions that are worse than the current incumbent, even if they were accepted. 
Each segment consists of a total of 100 iterations. At the end of each segment, the weight of each destroy and repair heuristic is updated using the following formula:

\begin{align}
	\eta_h = (1-p_{react})\eta_{h}+p_{react}\frac{\sigma_{h}}{\max(1,\Omega_{h})}
\end{align} 

where $\Omega_{h}$ denotes the number of times the considered repair heuristic was used and $p_{react}$ is a predetermined weight controlling the influence of the new score on the historic weight.

\subsection{Task Stacking}
To improve bandwidth usage, we introduce task stacking into our repair heuristics. 
$Stacking$ causes the repair algorithm to try to build stacks of similar tasks (the seed tasks being the one that is supposed to be inserted) and to insert all stacked tasks at once. Tasks are considered for stacking if they share starting and ending times and belong to the same task group as the seed task. 
Since stackable tasks are assigned in parallel, in the best case, an operator's capacity is fully used by the chosen tasks.

\subsection{Slice Shuffling}
In order to introduce some randomization into our repair heuristics, we develop a slice shuffling mechanism. As all possible assignments are always sorted in the same way whenever a given repair heuristic is applied, we introduce a semi-random shuffling operator in order to prevent the algorithm from generating the same solutions over and over. Slice shuffling takes the sorted list of possible assignments and divides it into slices of length $\mu$.  
The order of the assignments within a given slices is then shuffled. Preliminary experiments with different parameter settings have led to the definition of the set $sl$. The set $sl$ contains all possible values $\mu$ may take for a given iteration: at the start of each repair step, the value for $\mu$ is randomly chosen out of $sl$. Making sure that the slices are not too large allows us to explore different options for assignments, while ensuring that the initial sorting done by the repair heuristic does not become pointless. Too small slices may produce very similar results due to the potentially large number of tasks that do not differ in their sorting value.

\section{Computational Results}
\label{results}
The ALNS algorithm as well as the MIP model were implemented in Python, with the MIP model using the CPLEX 12.8 as MIP-solver. All tests are conducted on a computing cluster with 64 nodes consisting of 2 Intel Xeon X5570 CPUs with 4 cores as well as 48 GB of RAM each. Each run uses a single thread. All ALNS results are based on ten random runs per instance and we use a run time limit of 6 hours for the MIP-solver.  
Each time-bucket in the MIP represents five minutes.

\subsection{Data Sets}
The test instances used in this paper are based on information from our company partner Sportradar as well as on real-world sports data. Sportradar's operators reside in four different countries giving rise to different working and break length regulations. The preparation time $\rho$ is assumed to be 20 minutes irrespective of the working location. Tasks are sports matches and belong to one out of 22 different task groups and may require a maximum skill level of 100. In terms of bandwidth, a task may require the complete bandwidth (1) of an operator or only a fraction of the bandwidth. The minimum is $\frac{1}{6}$. This implies that the maximum number of parallel tasks is six. Furthermore, at most tasks from two different task groups may be scheduled in parallel. 
The generated test instances are divided into four different groups with ten instances each. Small instances contain only a handful of workers with around 100 tasks to be chosen for assignment and the considered planning horizon is limited to 8 hours. Medium-sized instances contain up to ten workers, between 400 and 700 tasks and a total planning horizon of 18 hours.  
The set of large instances contains a higher number of operators and is set to reflect the assignments for an entire day with a considered planning horizon of 24 hours and between 600 and 1100 tasks. Finally, ten very large-scale instances include shifts and tasks for a time span of 72 hours, this results in data sets with between 180 and 230 shifts and between 2000 and 3300 tasks. The length of the planning horizon corresponds roughly to the requirement of Sportradar which schedules their shifts three days in advance.
Instance names are given in the following format: $|T|$\_$|S|$\_$|V|$ providing the planning horizon of the instance in hours ($|T|$), the number of possible shifts ($|S|$), and the number of available tasks ($|V|$).

\subsection{Results for Benchmark Instances}
In a first step, we evaluate the performance of the developed ALNS on those instances that can also be tackled by the MIP-solver. 

Based on preliminary tests, all ALNS parameters have been set. The set of parameters is \{\tt{chancelimits}, \tt{widthlimits}, $sl$, $\rho$, $\epsilon_1$, $\epsilon_2$, $\epsilon_3$, $p_{react}$\}. 
The range \tt{chancelimits} which is used to define the probability for a task to be removed from the solution in the random removal operator, and the probability of an operator's shifts to be deleted from the solution is set to $(0.1,0.5)$. The range \tt{widthlimits} from which the value of the slice length in the time based removal operator is drawn is set to [180,300] (minutes).
The set $sl$ contains all possible values for the length of the slice $\mu$ which is used in the slice shuffling step. This set is defined to be \{0,4,8,16\}. 
The parameters used to reward destroy and repair operators for good performance \{$\epsilon_1$, $\epsilon_2$, $\epsilon_3$\} are initially set to \{40,25,8\}.  However, in the following we also test the setting \{40,25,0\}, i.e., no reward for deteriorating solutions that are accepted as new incumbent solutions. The value of $p_{react}$ is set to 0.1 for all computations.
The base setting of the weights in the objective function is $w_1 = 1$ and $w_2 = 1$.


Table~\ref{tbl:mipcomp} reports average values over small and medium-sized instances and the average average gap (AGap) as well as the average best gap (BGap) with respect to the MIP solution for setting $\epsilon_3 = 8$ and setting $\epsilon_3 = 0$ and different ALNS iteration limits (Iterations).

\begin{table}[tbh]
\setlength{\tabcolsep}{2ex}
\caption{Comparison of average solutions obtained by the ALNS using different values for $\epsilon_3$ in comparison to the best solution values obtained by the MIP-solver for small and medium-sized instances.\label{tbl:mipcomp}}
\centering
\begin{tabular}{lrrrr}
\toprule
\multicolumn{5}{l}{ALNS}\\
\midrule
Setting & Iterations & AGap  & BGap & Avg \\
\midrule
$\epsilon_3 = 8$ & 1,000& 3.27 & 1.78 & 5123.4\\
 &10,000& 1.57 & 0.63  & 5226.2 \\
&25,000& 1.14 & 0.39  & 5252.5 \\
&100,000& 0.67 & 0.09  & 5286.1 \\
\midrule
$\epsilon_3 = 0$ & 1,000& 3.22 & 1.98 & 5127.2\\
 &10,000& 1.48 & 0.52  & 5231.7\\
&25,000& 1.19 & 0.34 & 5249.8\\
&100,000& 0.91 & 0.22 & 5269.2\\
\bottomrule
\end{tabular}
\end{table}

Detailed results on a per instance level, can be found in the appendix in Tables \ref{tablestart} to \ref{tableend}, where Tables \ref{tablestart} to \ref{firstend} contain the results for setting $\epsilon_3 = 8$ and Tables \ref{secondstart} to \ref{tableend} those of setting $\epsilon_3 = 0$. All tables are structured as follows:  
for each instance, we provide the average objective value ($Avg$), the best objective value ($Best$), the average run time ($Time$) in seconds as well as the average ($AGap$) and the best gap ($BGap$) of the objective value computed by the ALNS to the objective value obtained with the MIP-solver in percent. Furthermore, we provide the average number of tasks assigned ($|M|$). For the solutions obtained with the MIP-solver, we give the best obtained lower bound ($LB$) and the run time ($Time$) in seconds. For instances that the MIP-solver did not solve within the time limit of six hours, we report the optimality gap ($MIPGap$) given by CPLEX at the end of the run time. In the final column we provide the number of tasks assigned in the best solution obtained by the MIP-solver ($|M|$). For each set of benchmark instances, we give the results for 1,000, 10,000, 25,000 as well as 100,000 iterations in separate tables. In each table, we add a summary line that provides the average of the average gaps as well as the average of the best gaps achieved over the instances of the benchmark set.

As the solutions obtained by the MIP-solver (given in Table \ref{tablestart} and repeated in Tables \ref{table10Tits} to \ref{tableend} for comparison purposes) show, most problems of the smallest size with a planning horizon of eight hours can be solved to optimality within the time limit. However, even for medium-sized instances that consider a planning horizon of 18 hours, the MIP-solver already reaches its limits. For large instances considering a planning horizon of a full day, the MIP implementation already fails at the root node. Therefore, 
in this initial set of experiments, we only report results for small and medium-sized instances. 

Overall, setting $\epsilon_3=8$ 
performs slightly better than setting $\epsilon_3=0$. This difference 
mainly 
becomes visible for the highest number of iterations when comparing the best objective values found. For the highest number of iterations tested, the best solutions obtained using $\epsilon_3=8$ are within less than 0.1 percent of the solution obtained by the MIP-solver. However, we note that this average consists of solutions where the heuristic significantly outperforms the solution of the MIP as well as some solutions where it falls off slightly. The maximum percentage difference of the heuristic beating the MIP implementation and vice versa is at about 1.5 percent. We note that while the MIP-solver was given an upper limit of six hours to calculate the solution, we chose the limit of 100,000 iterations for our longest comparison to stay considerably below 30 minutes of run time for the heuristic. We also note that our implementation was made in Python 3. Speed-ups of a factor of 10 may be achieved when using a different programming language \citep{tricoire2021broute}.
In the following, all reported ALNS results use the setting $\epsilon_3 = 8$.

\subsection{Additional Objectives and Trade-off Analysis \label{addobj}}

In addition to the two components of the objective function considered in the PTSP-TS, Sportradar was interested in optimizing an additional three objectives introduced in detail in the following paragraphs. We name them $Groups$, $Consec$, and $Workload$.

Tasks can be grouped according to their similarity. When similar tasks are performed within the same shift, the quality of the service increases. Adversely, the more different tasks from different groups a worker is assigned during a shift, the lower the quality the worker will be able to provide. The third objective is therefore to minimize the number of different task groups assigned to a full shift and is named $Groups$. While there is an upper limit to the number of tasks of different groups for concurrent tasks, this objective seeks to minimize the number for the whole shift. 

The fourth objective introduces the idea of consecutive tasks $Consec$ and adds a bonus if they are scheduled in the same shift. As some groups of tasks may feature tasks that should start back-to-back, it is generally helpful to assign these consecutive tasks to the same shift. This information is not directly exploited in the base setting of our ALNS. We explain below, how this information can be incorporated into the ALNS, so as to increase the number of consecutive tasks assigned to the same shift.

The final objective is to minimize the amount of employee idleness by maximizing the workload in percent of total available time. We name this measure $Workload$. This objective was omitted in the model proposed in this paper, as it is generally considered to be optimized through the choice of the most valuable tasks. Introducing this objective might incur assignments of lower priority tasks in order to reduce employee idle time. 

In order to evaluate the impact of considering these additional objectives, we evaluate different weight settings. Let \{$Priority$, $Penalty$, $Groups$, $Consec$, $Workload$\} denote the set of considered objectives. We combine them into a weighted sum where each objective receives a different weight, depending on the chosen focus. Weight setting \tt{Control} is the benchmark setting. It uses the same weights as above, i.e., \{1,1,0,0,0\}. Weight setting \tt{Priority} focuses on the first objective only, using weight set \{1,0,0,0,0\}. Setting \tt{Penalty} puts a comparably high weight on the second objective, using weight set \{1,100,0,0,0\}. The weights for setting \tt{TaskGroups}, where emphasis is put on grouping similar tasks together, are \{1,1,-10,0,0\}. We note that the $Groups$ and $Penalty$ objectives are only considered as secondary objectives, as obviously without optimization of $Priority$, the value of the $Groups$ objective would be 1 for solutions without parallel tasks of different groups and 0 (the best possible value) for solutions without any tasks assigned. The latter also holds for the $Penalty$ objective. The employed weights for the maximization of the $Workload$ objective (setting \tt{Workload}) are \{1,1,0,0,10000\}. 

Finally, we analyze a setting where all five objectives considered by the company receive a weight, so as to roughly reflect their importance from the company perspective: $Priority$ is the main objective, $Penalty$ and $Workload$ are secondary objectives, while $Groups$ and $Consec$ are the least important objectives. In this experiment, we introduce the concept of successor matching into the proposed ALNS: we add the possibility upon assigning a match to assign its direct predecessor/successor at the same time and to the same shift (if feasible). This is an additional step taken to improve the number of consecutive matches that are assigned to the same operator. Furthermore, in the destruction step of the ALNS, we introduce successor destruction, which allows us to destroy any assigned successors and predecessors of a destroyed match, even if they are assigned to different shifts in the current solution. Successor destruction is randomly turned on or off at the beginning of a new destroy step. These final tests are made using weights for the five objectives of \{1,1,-1,1,1000\}. We denote the ALNS with these additional ingredients ALNS+ and the weight setting \tt{AllObjectives}.

\begin{table}[tbh]
\setlength{\tabcolsep}{1.2ex}
\caption{Comparison of average solutions across all instances, obtained with 100,000 ALNS iterations using different weight settings. For setting \tt{AllObjectives} ALNS+ is used. \label{tbl:comparison}}

\small
\centering
\begin{tabular}{lp{3pt}rrrrrrr}
\toprule
 && \multicolumn{5}{l}{Average individual objective values}\\
 \cmidrule{3-7}
Weight setting && $Priority$ & $Penalty$ & $Groups$ & $Consec$ & $Workload$ & $OF$ & $OFsmall$\\
\midrule
\tt{Control} && 44733.6 & -206.55 & 2.34 & 11.05 & 0.86 & 44527.05 & 5286.10\\
\midrule
\tt{Priority} && 44875.28 & -482.92 & 2.34 & 11.00 & 0.86 & 44392.35 & 5264.68\\
\tt{Penalty} && 43998.70 & -0.00 & 2.32 & 10.70 & 0.86 & 43998.70 & 5234.90\\
\tt{TaskGroups} && 44728.35 & -206.06 & 2.28 & 11.18 & 0.86 & 44522.29 & 5288.38\\
\tt{Workload} && 44576.25 & -195.04 & 2.38 & 10.89 & 0.88 & 44381.21 & 5168.35\\
\midrule
\tt{AllObjectives} && 44751.4 & -202.16 & 2.32 & 23.55 & 0.87 & 44549.24 & 5288.87\\
\bottomrule
\end{tabular}
\end{table}

We summarize the results of the different weight settings in Table \ref{tbl:comparison}. Average results per instance can be found in Tables \ref{tbl:priority}--\ref{tbl:allobj}  in the appendix.

In Table \ref{tbl:comparison}, in addition to the average values for every single objective, we report the average values obtained for the original objective function ($OF$) as well as the average value of the original objective function considering only the small and medium-sized instances ($OFsmall$). The values given in the table show, that each of the four specialized settings reaches the best value for the considered objective among all approaches tested. Furthermore, the \tt{Control} setting, taking into account only priority and penalty, provides the best average value of the original objective function, considering all test instances. When considering small and medium-sized instances only, additional weight on the minimization of task groups (setting \tt{Taskgroups}) has a positive side effect on the penalty objective.

Finally, setting \tt{AllObjectives} 
obtains slightly better solutions on average for the original objective function, which indicates that the additional ingredients, focusing on consecutive matches, help the ALNS in finding even slightly better solutions for the original objective function by planning more consecutive matches together.

The results obtained for the different weight settings allow us to derive some managerial insights and pointers towards further use and practical applications. First, they 
indicate that secondary objectives may be considered at a comparatively small price when regarding the two main objectives. All results considering focused objective functions share a significant improvement in the focused objective over the baseline or control setting. 

Second, additional ingredients focusing on the planning of consecutive matches together with weights on all objectives (setting \tt{AllObjectives}) has a positive impact. It returns solutions that improve all three secondary objectives 
and even slightly improve the values on the two main objectives on average. This implies that additional information (in our case, the information relating to matches that can and should be planned consecutively) should be used and exploited in the design of the algorithm. 

In the following case study, where the proposed algorithm is tested on company data, ALNS+, as deployed in the \tt{AllObjectives} setting, is used, and compared to ALNS with the setting \tt{Control}.

\section{Case Study}
\label{study}

The considered problem was brought to us by Sportradar. Operators are to be assigned sports matches to supervise and determine whether provided betting odds reflect reality. The considered problem includes all five of the previously presented objectives. Furthermore, Sportradar requires a time horizon of three days to be planned at once. The comparison made in this section is only performed between the solutions obtained with ALNS+ with the setting \tt{AllObjectives}, ALNS with the setting \tt{Control} and the assignments the company has made.

\begin{table}[tbh]
\setlength{\tabcolsep}{2ex}
\caption{Comparison of original company assignments with average solutions obtained with ALNS+ using weight setting \tt{AllObjectives} on case study data,
as well as weighting the two main objectives only (\tt{Control}) using ALNS \label{tbl:rw}}
\centering
\begin{tabular}{lp{3pt}rrr}
\toprule
Objective && Company & \tt{AllObjectives} &
\tt{Control}\\
\midrule
Total Priority ($Priority$) && 111390 & 179902.0 & 179865.0\\
\\
Total Penalty ($Penalty$) && -10577 & -752.6 & -816.7\\
\\
Average sports ($Groups$) && 1.982 & 2.553 & 2.515\\
Maximum sports && 5 & 6.2 & 6.1\\
\\
Consecutive same ($Consec$) && 12 & 23.2 & 18.7\\
Consecutive different && 16 & 82.4 & 82.9\\
Consecutive scheduled && 22 & 82.6 & 83.0\\
Consecutive available && 83 & 83.0 & 83.0\\
\\
Ratio workingtime/total ($Workload$)&& 0.822 & 0.841 & 0.841\\
\\
Scheduled matches && 1584 & 2684.8 & 2696.6\\
Total matches && 5266 & 5266.0 & 5266.0\\
\\
Objective Value ($OF$) && 100813 & 179149.4 & 179048.3\\
\bottomrule
\end{tabular}
\end{table}

As the basis for the comparison between the performance of our solution method and the original company assignments, we use company data spanning a total of five days. The resulting data set comprises a total of 6706 matches assignable to a total of 379 potential shifts which belong to 124 operators. To increase the comparability between test assignments and original assignments, as well as to simulate the continuity of the real world problem, we choose to exclude assignments made for the first and the final of these five days from contributing to the objective function. This leaves a total of 5266 matches available for assignment within the time frame of three days. Table \ref{tbl:rw} provides this comparison on real-world data using the proposed ALNS+ algorithm, the ALNS algorithm and the assignments made by the company.  
ALNS is run 
only considering the two main objectives (weight setting \tt{Control}) while 
ALNS+ uses weights for all five objectives (weight setting \tt{AllObjectives}). The values provided in the table are obtained for an iteration limit of 100,000 iterations for both  weight settings. 
The comparison shows that assignments made using the proposed method significantly outperform past company assignments when regarding the two main objectives. The third objective $Groups$ shows that our ALNS+ assigns more tasks of different task groups than the company solution, which is only treated as a secondary objective. The same holds true for the highest value ("Maximum Sports") over all shifts. Comparison for the objective of assigning consecutive matches $Consec$ shows that the generated assignments include many more consecutive matches than the company solution. In addition to the actual objective of consecutive matches assigned to the same shift, we further report the values for consecutive matches assigned to any shift ("Consecutive different"), including same and different shifts, as well as consecutive matches where at least one of the two matches is assigned in the overall solution ("Consecutive scheduled"). The reported ratio of working time to total time ($Workload$) shows that our assignments achieve an average of 0.841 for both settings, which is significantly higher than the value of the company assignments. Finally, we report the number of scheduled matches in the solutions, as well as the value obtained for the objective function ($OF$) used in the \tt{Control} setting.

Summarizing the above, the proposed heuristic significantly outperforms a comparable assignment made by Sportradar in all considered performance measures but one ($Groups$). The large gap in the objective value of the main two objectives can partially be explained by the limit of the scale of importance of each of the considered matches. As the matches are generally assigned a priority between 0 and 100, the company solution considered a direct approach to this goal. A task with a higher priority was therefore assigned as early as possible. However, long matches with a high value for priority may be inferior to short matches with an average value due to the amount of working capacity they require from a given worker. This is very clearly displayed in the comparison when regarding the values for the fifth objective, minimizing worker idle time and the total number of scheduled matches in the solutions. While our solutions assign more than 1,000 additional matches, the ratio of working time to total time on average is only around two percent higher than in the company solution.  

\section{Conclusions}
\label{conc}
In this paper we have modeled and solved a personnel task scheduling problem with task selection (PTSP-TS). We have developed a tailored adaptive large neighborhood search algorithm. Repair and destroy operators previously used in the literature have been adapted to fit the proposed problem. Additionally, we propose new and tailored operators. Furthermore, we have proposed a mathematical model of the considered problem and benchmark the ALNS algorithm against solving the MIP formulation with CPLEX. The required run time of CPLEX is long even for medium-sized instances and cannot be used for time horizons interesting for real-world application. The proposed ALNS has proven very competitive compared to the previous planning at Sportradar
and has since been implemented for regular use.\\
Future research will focus on further analyzing the trade-off between the different objectives, e.g., by considering a subset of the objectives concurrently in a multi-objective approach which can produce (an approximation of) the Pareto frontier. 


\section*{Acknowledgements}
This research was funded in whole, or in part, by the Austrian Science Fund (FWF) [P 31366]. For the purpose of open access, the author has applied a CC BY public copyright licence to any Author Accepted Manuscript version arising from this submission.
We also wish to thank Sportradar for having provided us with the real-world data.


\bibliographystyle{apalike}      
